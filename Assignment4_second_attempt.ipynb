{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_second_attempt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZAoTNv2LVrV4ijfFUfl/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuptaNavdeep1983/CS767/blob/main/Assignment4_second_attempt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWMXWXeEm9vL"
      },
      "source": [
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIukojRanEG3"
      },
      "source": [
        "iris = load_iris()\n",
        "\n",
        "iris_columns = ['sepal_len', 'sepal_width', 'petal_length', 'petal_width', 'target']\n",
        "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris_columns)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2VTt2ZmnBUo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X = df[['sepal_len', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "X = df[['sepal_width', 'petal_length']]\n",
        "\n",
        "scaler_training = StandardScaler() \n",
        "scaler_training.fit(X)\n",
        "scaled_values_training = scaler_training.transform(X)\n",
        "\n",
        "X = pd.DataFrame(scaled_values_training, columns=[*X.columns.values])\n",
        "X['target'] = df['target']\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7xVPtr6XuDim",
        "outputId": "d3a83fa4-4a88-4f9e-a7f3-1a8158b894d1"
      },
      "source": [
        "X"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.019004</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.131979</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.328414</td>\n",
              "      <td>-1.397064</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.098217</td>\n",
              "      <td>-1.283389</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.249201</td>\n",
              "      <td>-1.340227</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>-0.131979</td>\n",
              "      <td>0.819596</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>-1.282963</td>\n",
              "      <td>0.705921</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>-0.131979</td>\n",
              "      <td>0.819596</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.788808</td>\n",
              "      <td>0.933271</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>-0.131979</td>\n",
              "      <td>0.762758</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_width  petal_length  target\n",
              "0       1.019004     -1.340227     0.0\n",
              "1      -0.131979     -1.340227     0.0\n",
              "2       0.328414     -1.397064     0.0\n",
              "3       0.098217     -1.283389     0.0\n",
              "4       1.249201     -1.340227     0.0\n",
              "..           ...           ...     ...\n",
              "145    -0.131979      0.819596     2.0\n",
              "146    -1.282963      0.705921     2.0\n",
              "147    -0.131979      0.819596     2.0\n",
              "148     0.788808      0.933271     2.0\n",
              "149    -0.131979      0.762758     2.0\n",
              "\n",
              "[150 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P-rkI38rAhm",
        "outputId": "912abc0a-e335-4142-bdc8-5d2e79a63c4f"
      },
      "source": [
        "from math import exp\n",
        "from random import seed\n",
        "from random import random\n",
        " \n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        " \n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        " \n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        " \n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        " \n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        " \n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        " \n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        " \n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "  for epoch in range(n_epoch):\n",
        "    sum_error = 0\n",
        "    for row in train:\n",
        "      outputs = forward_propagate(network, row)\n",
        "      expected = [0 for i in range(n_outputs)]\n",
        "      expected[int(row[-1])] = 1\n",
        "      sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "      backward_propagate_error(network, expected)\n",
        "      update_weights(network, row, l_rate)\n",
        "    print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        " \n",
        "# Test training backprop algorithm\n",
        "seed(68)\n",
        "dataset = X.values\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 3, n_outputs)\n",
        "print(network)\n",
        "train_network(network, dataset, 0.5, 100, n_outputs)\n",
        "for layer in network:\n",
        "\tprint(layer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[{'weights': [0.7416689356145733, 0.9408038831472155, 0.7474033968541627]}, {'weights': [0.9081425629614371, 0.11097728168000565, 0.579773181999968]}, {'weights': [0.4318673124107113, 0.26549257874510634, 0.8604091679690017]}], [{'weights': [0.32940149633680194, 0.9736705910655336, 0.36125339691759495, 0.5536247242149994]}, {'weights': [0.7742260752576486, 0.7817480945876376, 0.041785415602753395, 0.7335413506775065]}, {'weights': [0.1060683270342535, 0.3424554918369298, 0.09338908488068065, 0.6053788824313064]}]]\n",
            ">epoch=0, lrate=0.500, error=61.438\n",
            ">epoch=1, lrate=0.500, error=57.219\n",
            ">epoch=2, lrate=0.500, error=44.793\n",
            ">epoch=3, lrate=0.500, error=40.300\n",
            ">epoch=4, lrate=0.500, error=38.923\n",
            ">epoch=5, lrate=0.500, error=38.040\n",
            ">epoch=6, lrate=0.500, error=37.378\n",
            ">epoch=7, lrate=0.500, error=36.598\n",
            ">epoch=8, lrate=0.500, error=35.278\n",
            ">epoch=9, lrate=0.500, error=33.263\n",
            ">epoch=10, lrate=0.500, error=30.739\n",
            ">epoch=11, lrate=0.500, error=27.995\n",
            ">epoch=12, lrate=0.500, error=25.254\n",
            ">epoch=13, lrate=0.500, error=22.657\n",
            ">epoch=14, lrate=0.500, error=20.290\n",
            ">epoch=15, lrate=0.500, error=18.208\n",
            ">epoch=16, lrate=0.500, error=16.454\n",
            ">epoch=17, lrate=0.500, error=15.040\n",
            ">epoch=18, lrate=0.500, error=13.934\n",
            ">epoch=19, lrate=0.500, error=13.080\n",
            ">epoch=20, lrate=0.500, error=12.419\n",
            ">epoch=21, lrate=0.500, error=11.903\n",
            ">epoch=22, lrate=0.500, error=11.494\n",
            ">epoch=23, lrate=0.500, error=11.166\n",
            ">epoch=24, lrate=0.500, error=10.899\n",
            ">epoch=25, lrate=0.500, error=10.679\n",
            ">epoch=26, lrate=0.500, error=10.496\n",
            ">epoch=27, lrate=0.500, error=10.343\n",
            ">epoch=28, lrate=0.500, error=10.213\n",
            ">epoch=29, lrate=0.500, error=10.102\n",
            ">epoch=30, lrate=0.500, error=10.008\n",
            ">epoch=31, lrate=0.500, error=9.927\n",
            ">epoch=32, lrate=0.500, error=9.858\n",
            ">epoch=33, lrate=0.500, error=9.798\n",
            ">epoch=34, lrate=0.500, error=9.748\n",
            ">epoch=35, lrate=0.500, error=9.705\n",
            ">epoch=36, lrate=0.500, error=9.668\n",
            ">epoch=37, lrate=0.500, error=9.637\n",
            ">epoch=38, lrate=0.500, error=9.612\n",
            ">epoch=39, lrate=0.500, error=9.591\n",
            ">epoch=40, lrate=0.500, error=9.574\n",
            ">epoch=41, lrate=0.500, error=9.560\n",
            ">epoch=42, lrate=0.500, error=9.550\n",
            ">epoch=43, lrate=0.500, error=9.543\n",
            ">epoch=44, lrate=0.500, error=9.538\n",
            ">epoch=45, lrate=0.500, error=9.536\n",
            ">epoch=46, lrate=0.500, error=9.535\n",
            ">epoch=47, lrate=0.500, error=9.536\n",
            ">epoch=48, lrate=0.500, error=9.539\n",
            ">epoch=49, lrate=0.500, error=9.543\n",
            ">epoch=50, lrate=0.500, error=9.548\n",
            ">epoch=51, lrate=0.500, error=9.555\n",
            ">epoch=52, lrate=0.500, error=9.562\n",
            ">epoch=53, lrate=0.500, error=9.570\n",
            ">epoch=54, lrate=0.500, error=9.578\n",
            ">epoch=55, lrate=0.500, error=9.587\n",
            ">epoch=56, lrate=0.500, error=9.597\n",
            ">epoch=57, lrate=0.500, error=9.607\n",
            ">epoch=58, lrate=0.500, error=9.617\n",
            ">epoch=59, lrate=0.500, error=9.628\n",
            ">epoch=60, lrate=0.500, error=9.638\n",
            ">epoch=61, lrate=0.500, error=9.649\n",
            ">epoch=62, lrate=0.500, error=9.660\n",
            ">epoch=63, lrate=0.500, error=9.671\n",
            ">epoch=64, lrate=0.500, error=9.682\n",
            ">epoch=65, lrate=0.500, error=9.693\n",
            ">epoch=66, lrate=0.500, error=9.704\n",
            ">epoch=67, lrate=0.500, error=9.715\n",
            ">epoch=68, lrate=0.500, error=9.726\n",
            ">epoch=69, lrate=0.500, error=9.737\n",
            ">epoch=70, lrate=0.500, error=9.749\n",
            ">epoch=71, lrate=0.500, error=9.760\n",
            ">epoch=72, lrate=0.500, error=9.771\n",
            ">epoch=73, lrate=0.500, error=9.782\n",
            ">epoch=74, lrate=0.500, error=9.793\n",
            ">epoch=75, lrate=0.500, error=9.804\n",
            ">epoch=76, lrate=0.500, error=9.815\n",
            ">epoch=77, lrate=0.500, error=9.826\n",
            ">epoch=78, lrate=0.500, error=9.837\n",
            ">epoch=79, lrate=0.500, error=9.848\n",
            ">epoch=80, lrate=0.500, error=9.859\n",
            ">epoch=81, lrate=0.500, error=9.871\n",
            ">epoch=82, lrate=0.500, error=9.882\n",
            ">epoch=83, lrate=0.500, error=9.893\n",
            ">epoch=84, lrate=0.500, error=9.905\n",
            ">epoch=85, lrate=0.500, error=9.916\n",
            ">epoch=86, lrate=0.500, error=9.928\n",
            ">epoch=87, lrate=0.500, error=9.940\n",
            ">epoch=88, lrate=0.500, error=9.951\n",
            ">epoch=89, lrate=0.500, error=9.963\n",
            ">epoch=90, lrate=0.500, error=9.975\n",
            ">epoch=91, lrate=0.500, error=9.987\n",
            ">epoch=92, lrate=0.500, error=9.999\n",
            ">epoch=93, lrate=0.500, error=10.010\n",
            ">epoch=94, lrate=0.500, error=10.022\n",
            ">epoch=95, lrate=0.500, error=10.034\n",
            ">epoch=96, lrate=0.500, error=10.046\n",
            ">epoch=97, lrate=0.500, error=10.057\n",
            ">epoch=98, lrate=0.500, error=10.069\n",
            ">epoch=99, lrate=0.500, error=10.081\n",
            "[{'weights': [-0.7670839005124004, 9.264142143187623, -5.210931228775041], 'output': 0.876061938332551, 'delta': 0.0011934270019654555}, {'weights': [1.478727202894932, -5.2503695793528875, -2.5226948926562582], 'output': 0.0012019243038442543, 'delta': 1.1781966167912381e-05}, {'weights': [0.5076367898475092, -7.110689153566674, 4.033659739026205], 'output': 0.18905615170850187, 'delta': -0.001150696179897161}]\n",
            "[{'weights': [-4.308560892338286, 7.246578340001664, -0.040304429341500844, -3.429018221730288], 'output': 0.0007441720199127802, 'delta': -5.533798787133721e-07}, {'weights': [-5.62475762342897, -8.13642836678003, 3.5127109899723847, 1.046286342426479], 'output': 0.03820762252690383, 'delta': -0.0014040460752108544}, {'weights': [5.933316848687775, -3.080224777611955, -4.936896291418807, -0.5158322230181861], 'output': 0.9769010469499204, 'delta': 0.0005212369169226632}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}