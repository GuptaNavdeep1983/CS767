{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNt+eZz49HdkGWvArcox/x+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuptaNavdeep1983/CS767/blob/main/PingPong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg3pfTqXoUxx"
      },
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWpEfAcko4dG",
        "outputId": "86c89789-093f-4e1f-9185-fa57fa9e6452"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Roms.rar', <http.client.HTTPMessage at 0x7f3e3072ff50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sql33Dw-o-rv",
        "outputId": "3adf6579-70c0-42dc-ca24-5b541dcf2b2c"
      },
      "source": [
        "!pip install unrar\n",
        "!unrar x Roms.rar"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unrar in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "Extracting  HC ROMS.zip                                                  \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  ROMS.zip                                                     \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7BH8Q9WpUOu",
        "outputId": "8aaa8664-1525-49e5-c018-38bbae44e180"
      },
      "source": [
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘rars’: File exists\n",
            "copying adventure.bin from ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying amidar.bin from ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying assault.bin from ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n",
            "copying asteroids.bin from ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying crazy_climber.bin from ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying defender.bin from ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying elevator_action.bin from ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying enduro.bin from ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying gravitar.bin from ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying hero.bin from ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying jamesbond.bin from ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying journey_escape.bin from ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying keystone_kapers.bin from ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying koolaid.bin from ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying kung_fu_master.bin from ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying laser_gates.bin from ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying lost_luggage.bin from ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying montezuma_revenge.bin from ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying mr_do.bin from ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying ms_pacman.bin from ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying pacman.bin from ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying phoenix.bin from ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying video_pinball.bin from ROMS/Pinball (AKA Video Pinball) (Zellers).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying pitfall.bin from ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying sir_lancelot.bin from ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying skiing.bin from ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying star_gunner.bin from ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying surround.bin from ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying time_pilot.bin from ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying trondead.bin from ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying up_n_down.bin from ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying venture.bin from ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying wizard_of_wor.bin from ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-jErg3qemj"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkRg5YMxqvW8",
        "outputId": "0bf5aed2-1190-4f17-dfcf-14af1d2040b7"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f3e2e0a8810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDK2stwcoYuQ"
      },
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "mbG834QNpieT",
        "outputId": "c6e1db44-d29c-413d-ea25-ae6ae6bfb19d"
      },
      "source": [
        "first_frame = env.reset()\n",
        "plt.imshow(first_frame)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3e302c0250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "FbJ8rtd5pnlg",
        "outputId": "390446e2-8151-46be-89c2-0dc0ef0a4443"
      },
      "source": [
        "next_frame, next_frames_reward, done, info = env.step(1)\n",
        "\n",
        "plt.imshow(next_frame)\n",
        "print('Reward Recieved = ' + str(next_frames_reward))\n",
        "print('Next state is a terminal state: ' + str(done))\n",
        "print('info[ale.lives] tells us how many lives we have. Lives: ' + str(info['ale.lives']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward Recieved = 0.0\n",
            "Next state is a terminal state: False\n",
            "info[ale.lives] tells us how many lives we have. Lives: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "5rwbrcr0qLtO",
        "outputId": "81c5fe1c-cd4f-4b75-c018-8b10ee4de4d7"
      },
      "source": [
        "for i in range(10000):\n",
        "    a = random.sample([0,1,2,3] , 1)[0]\n",
        "    f_p,r,d,info = env.step(a)\n",
        "    screen = env.render(mode='rgb_array')\n",
        "    plt.imshow(screen)\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "    ipythondisplay.display(plt.gcf())\n",
        "    if d == True:\n",
        "        env.reset()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-34d1003dd2d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mipythondisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mipythondisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2103\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2104\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m                     bbox = ax.get_tightbbox(renderer,\n\u001b[0;32m-> 2395\u001b[0;31m                             bbox_extra_artists=bbox_extra_artists)\n\u001b[0m\u001b[1;32m   2396\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m                     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4325\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4327\u001b[0;31m             \u001b[0mbb_yaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_yaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4329\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_yaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                   if 0 < b.width < np.inf and 0 < b.height < np.inf]\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36munion\u001b[0;34m(bboxes)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mxmax\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;34m\"\"\"The right edge of the bounding box.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAD8CAYAAAA/rZtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARiElEQVR4nO3df4xdZZ3H8fdnph1aS3GmFiopVfoLY924BbtAskrcFUshGyubyJZsEBfSakITjC6bImZpNmuyuBazuruYEohldQEXREkWd+0SgouA0GothYKUWqRDmWp16dDWTmfmu3+cM+XOdG7n3ufcO/cHn1dyc895zq/npPfTe+4z536vIgIzq05Hoztg1oocHLMEDo5ZAgfHLIGDY5bAwTFLULfgSFoh6QVJuyStq9dxzBpB9fg7jqRO4BfAR4G9wNPAlRHxXM0PZtYA9XrHOR/YFRG7I2IAuAdYWadjmU26KXXa71zglZL5vcAF5VaW5NsXrBn9JiJOH29BvYIzIUlrgDWNOr5ZBV4ut6BewekF5pXMn5W3HRcRG4GN4Hccaz31+ozzNLBY0nxJXcAq4ME6Hcts0tXlHSciBiWtBf4b6ATujIhn63Ess0aoy3B01Z1owku1q666ioULF1a8/sGDB7n11luPz0vi5ptvruqY9913Hzt27Dg+f8EFF3DppZdWtY/169dXtf5EZs+ezdq1a6vaZsOGDfT399e0H2N98YtfZMqUN//f//rXv86BAwdqfZitEbFsvAUNGxxodtOnT+e0006reP3h4eET2qrZHhj1QgDo6uqqah/1+E+wo6Oj6vOQVPN+jDVz5kymTp16fL6jY3JvgnFwKvTYY4/x4x//+Pj8ggUL+MQnPlHVPjZs2MDg4ODx+dWrVzNr1qyKt+/t7eVb3/rW8flp06Zx/fXXV9WHah04cIBbbrnlpOvccMMNk/7CbTQHp0JvvPEGfX19x+d7enqq3kdfX9+o4JROV+LYsWOj+jB9+vSq+1CtoaGhUce0jINjJ9Xd3c2qVatOus5kXJo1GwfHTqqrq4tzzjmn0d1oOg6OVWVoaIh77733pOscOXJkknrTOA6OVWV4eJgtW7Y0uhsN5+BUaNGiRaNGjmbPnl31PpYvXz5q2HrGjBlVbd/d3c2KFSuOz5cOx06Wjo6OUX0YzyOPPMLRo0cnqUeN4eBUaNGiRSxatKjQPi6++OJC23d3d7N8+fJC+yiqs7Nzwj48/vjjDs5b1fPPP8/vfve7itcf77r+iSeeqOqYY//y/dprr1W9j1o7cuRI1X0YGBioU2/e9NRTT426Apjsz1W+5casvOa+5WbatGnMnz+/0d0wG2Xnzp1llzVFcGbPns3q1asb3Q2zUT73uc+VXfbWusHIrEYcHLMEDo5ZAgfHLEFycCTNk/SIpOckPSvp+rx9vaReSdvyx2W1665ZcygyqjYIfD4ifippJrBV0uZ82Vcj4ivFu2fWnJKDExH7gH35dL+knWSFCM3aXk0+40g6GzgX+EnetFbSdkl3Sqr+q5JmTa5wcCSdCtwPfDYiDgK3AQuBpWTvSBvKbLdG0hZJWw4dOlS0G2aTqlBwJE0lC823I+K7ABHRFxFDETEM3E5WgP0EEbExIpZFxLJqb683a7Qio2oC7gB2RsStJe1nlqx2ObBj7LZmra7IqNofA1cBz0jalrd9AbhS0lIggD3Apwv10KwJFRlVewwYr7zJQ+ndMWsNvnPALEFTfK1gInfccQevvvpqo7thbWTu3Llcc801ydu3RHD6+/ur+hqz2USqrYc9li/VzBI4OGYJHByzBA6OWQIHxyyBg2OWwMExS+DgmCVwcMwSODhmCRwcswQOjlkCB8csgYNjlqDw1wok7QH6gSFgMCKWSZoF3AucTfb16Ssiwt8LsLZRq3ecP4mIpSW/XrUOeDgiFgMP5/NmbaNel2orgU359Cbg43U6jllD1CI4AfxQ0lZJa/K2OXmJXIDXgDk1OI5Z06jFV6c/GBG9ks4ANkt6vnRhRMR4P46bh2wNQE+Pq+Raayn8jhMRvfnzfuABssqdfSOFCfPn/eNs50qe1rKKlsCdkf/EB5JmAMvJKnc+CFydr3Y18P0ixzFrNkUv1eYAD2TVcJkC/HtE/Jekp4HvSLoWeBm4ouBxzJpKoeBExG7gD8dpPwB8pMi+zZqZ7xwwS9ASBQn/adkypi9a1OhuWBs50tPDLwts3xLBOXXKFGZ2dTW6G9ZGOqcUe+n7Us0sgYNjlsDBMUvg4JglaInBgXjHUYanH250N6yNxNumFdq+JYLD2wahc7DRvbA2EqcUez35Us0sgYNjlsDBMUvg4JglaInBgWOdwwxM8eCA1c5g53Ch7VsiOIenDRBTBhrdDWsjRwq+nnypZpbAwTFLkHypJuk9ZNU6RywA/hboBlYDv87bvxARDyX30KwJJQcnIl4AlgJI6gR6yarc/BXw1Yj4Sk16aNaEajU48BHgpYh4OS/cUVsdMNxxQmk2s2RR8ENKrYKzCri7ZH6tpE8CW4DPFy24fnDeIFOnHiuyC7NRjh0bhNfTty88OCCpC/gY8B95023AQrLLuH3AhjLbrZG0RdKWQ4cOFe2G2aSqxajapcBPI6IPICL6ImIoIoaB28kqe57AlTytldUiOFdScpk2Uvo2dzlZZU+ztlLoM05e9vajwKdLmr8saSnZrxjsGbPMrC0UreR5CHjHmLarCvXIrAW0xL1qm2MOB4eLfdXVrNTbo5s/KrB9SwRnGBimDn8fsres4YJ/FvS9amYJHByzBA6OWQIHxyxBSwwODD31MY4d9q8VWO0MzhiA95zw07QVa4ngxP/NIQ7ObHQ3rI3EsX7G+U3nivlSzSyBg2OWwMExS+DgmCVoicGBvn2b2f9r11Wz2hk4owt4Z/L2LRGcV16+h1/96leN7oa1kYEj7wauT97el2pmCRwcswQOjlmCioIj6U5J+yXtKGmbJWmzpBfz5568XZK+JmmXpO2SzqtX580apdJ3nG8CK8a0rQMejojFwMP5PGRVbxbnjzVk5aLM2kpFwYmIHwG/HdO8EtiUT28CPl7SfldkngS6x1S+MWt5RT7jzImIffn0a8CcfHou8ErJenvztlFckNBaWU0GByIiyMpBVbONCxJayyoSnL6RS7D8eeQe7V5gXsl6Z+VtZm2jSHAeBK7Op68Gvl/S/sl8dO1C4PWSSzqztlDRLTeS7gY+DMyWtBe4GfgH4DuSrgVeBq7IV38IuAzYBRwm+70cs7ZSUXAi4soyiz4yzroBXFekU2bNzncOmCVwcMwSODhmCRwcswQOjlkCB8csgYNjlsDBMUvg4JglcHDMEjg4ZgkcHLMEDo5ZAgfHLIGDY5bAwTFL4OCYJZgwOGWqeP6jpOfzSp0PSOrO28+WdETStvzxjXp23qxRKnnH+SYnVvHcDPxBRLwf+AVwY8mylyJiaf74TG26adZcJgzOeFU8I+KHETGYzz5JVgLK7C2jFp9xrgF+UDI/X9LPJD0q6UPlNnIlT2tlhX6RTdJNwCDw7bxpH/CuiDgg6QPA9yS9LyIOjt02IjYCGwHmzZtXVRVQs0ZLfseR9Cngz4C/zEtCERFHI+JAPr0VeAk4pwb9NGsqScGRtAL4G+BjEXG4pP10SZ359AKyn/rYXYuOmjWTCS/VylTxvBE4BdgsCeDJfATtIuDvJB0DhoHPRMTYnwcxa3kTBqdMFc87yqx7P3B/0U6ZNTvfOWCWwMExS+DgmCVwcMwSODhmCRwcswQOjlkCB8csgYNjlsDBMUvg4JglcHDMEjg4ZgkcHLMEDo5ZAgfHLIGDY5YgtZLnekm9JRU7LytZdqOkXZJekHRJvTpu1kiplTwBvlpSsfMhAElLgFXA+/Jt/nWkeIdZO0mq5HkSK4F78jJRvwR2AecX6J9ZUyryGWdtXnT9Tkk9edtc4JWSdfbmbSdwJU9rZanBuQ1YCCwlq965ododRMTGiFgWEctmzJiR2A2zxkgKTkT0RcRQRAwDt/Pm5VgvMK9k1bPyNrO2klrJ88yS2cuBkRG3B4FVkk6RNJ+skudTxbpo1nxSK3l+WNJSIIA9wKcBIuJZSd8BniMrxn5dRAzVp+tmjVPTSp75+l8CvlSkU2bNzncOmCVwcMwSODhmCRwcswQOjlkCB8csgYNjlsDBMUvg4JglcHDMEjg4ZgkcHLMEDo5ZAgfHLIGDY5bAwTFLkFqQ8N6SYoR7JG3L28+WdKRk2Tfq2XmzRpnwG6BkBQn/GbhrpCEi/mJkWtIG4PWS9V+KiKW16qBZM6rkq9M/knT2eMskCbgC+NPadsusuRX9jPMhoC8iXixpmy/pZ5IelfShgvs3a0qVXKqdzJXA3SXz+4B3RcQBSR8AvifpfRFxcOyGktYAawB6enrGLjZrasnvOJKmAH8O3DvSlteMPpBPbwVeAs4Zb3tX8rRWVuRS7WLg+YjYO9Ig6fSRXyeQtICsIOHuYl00az6VDEffDTwBvEfSXknX5otWMfoyDeAiYHs+PH0f8JmIqPSXDsxaRmpBQiLiU+O03Q/cX7xbZs3Ndw6YJXBwzBI4OGYJHByzBA6OWYKWD87l8+bx+CWX8OVzz210V+wtpOWDA9Ahkd1vajY52iI4ZpPNwTFLUPTu6Jo42DnM5tMOlV3+emf5nxH9wauv8r/79zMwPFyPrlmLumHJEi4644yyyzs7Ozn10UeT998UwQngaEeUXX6ySPx+aIjfD/n3eW2006ZO5fRp006+0tGjyfv3pZpZAgfHLEFTXKqZ1dqm3bv5z97essvPnjGDz773vcn7d3CsLe3q72dXf3/Z5W8MDhbav4Njb0m9hw/z9888k7y9IsqPZk2WrrefGu+88P1ll/c9+QwDB9+YxB6ZAbA1IpaNuyQiTvoA5gGPAM8BzwLX5+2zgM3Ai/lzT94u4GvALmA7cF4Fxwg//GjCx5Zyr9lKRtUGgc9HxBLgQuA6SUuAdcDDEbEYeDifB7iUrEjHYrLyT7dVcAyzljJhcCJiX0T8NJ/uB3YCc4GVwKZ8tU3Ax/PplcBdkXkS6JZ0Zs17btZAVf0dJy+Fey7wE2BOROzLF70GzMmn5wKvlGy2N28zaxsVj6pJOpWsgs1nI+Jg6W38ERGSopoDl1byNGs1Fb3jSJpKFppvR8R38+a+kUuw/Hl/3t5LNqAw4qy8bZTSSp6pnTdrlEoKEgq4A9gZEbeWLHoQuDqfvhr4fkn7J5W5EHi95JLOrD1UMFT8QbKhue3AtvxxGfAOstG0F4H/AWaVDEf/C1nd6GeAZR6O9qNFH2WHo5viD6DVfj4ymyRl/wDqu6PNEjg4ZgkcHLMEDo5ZAgfHLEGzfB/nN8Ch/LldzKZ9zqedzgUqP593l1vQFMPRAJK2tNNdBO10Pu10LlCb8/GlmlkCB8csQTMFZ2OjO1Bj7XQ+7XQuUIPzaZrPOGatpJneccxaRsODI2mFpBck7ZK0buItmo+kPZKekbRN0pa8bZakzZJezJ97Gt3PciTdKWm/pB0lbeP2P/+6yNfyf6/tks5rXM/HV+Z81kvqzf+Ntkm6rGTZjfn5vCDpkooOMtEt//V8AJ1kXz9YAHQBPweWNLJPieexB5g9pu3LwLp8eh1wS6P7eZL+XwScB+yYqP9kXyn5AdnXRy4EftLo/ld4PuuBvx5n3SX56+4UYH7+euyc6BiNfsc5H9gVEbsjYgC4h6zYRzsoV8yk6UTEj4Dfjmlu2WIsZc6nnJXAPRFxNCJ+SVbW7PyJNmp0cNqlsEcAP5S0Na+lAOWLmbSKdizGsja/vLyz5NI56XwaHZx28cGIOI+sptx1ki4qXRjZNUHLDl+2ev9ztwELgaXAPmBDkZ01OjgVFfZodhHRmz/vBx4ge6svV8ykVRQqxtJsIqIvIoYiYhi4nTcvx5LOp9HBeRpYLGm+pC5gFVmxj5YhaYakmSPTwHJgB+WLmbSKtirGMuZz2OVk/0aQnc8qSadImk9WgfapCXfYBCMglwG/IBvNuKnR/Uno/wKyUZmfk9XWvilvH7eYSTM+gLvJLl+OkV3jX1uu/yQUY2mS8/m3vL/b87CcWbL+Tfn5vABcWskxfOeAWYJGX6qZtSQHxyyBg2OWwMExS+DgmCVwcMwSODhmCRwcswT/D0xUD+y2dn1+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpHs-F1Brha4"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def resize_frame(frame):\n",
        "    frame = frame[30:-12,5:-4]\n",
        "    frame = np.average(frame,axis = 2)\n",
        "    frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST)\n",
        "    frame = np.array(frame,dtype = np.uint8)\n",
        "    return frame"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejw_XRQr5Gi"
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class Memory():\n",
        "    def __init__(self,max_len):\n",
        "        self.max_len = max_len\n",
        "        self.frames = deque(maxlen = max_len)\n",
        "        self.actions = deque(maxlen = max_len)\n",
        "        self.rewards = deque(maxlen = max_len)\n",
        "        self.done_flags = deque(maxlen = max_len)\n",
        "\n",
        "    def add_experience(self,next_frame, next_frames_reward, next_action, next_frame_terminal):\n",
        "        self.frames.append(next_frame)\n",
        "        self.actions.append(next_action)\n",
        "        self.rewards.append(next_frames_reward)\n",
        "        self.done_flags.append(next_frame_terminal)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tki1w391sNmp"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def initialize_new_game(name, env, agent):\n",
        "    \"\"\"We don't want an agents past game influencing its new game, so we add in some dummy data to initialize\"\"\"\n",
        "    \n",
        "    env.reset()\n",
        "    starting_frame = resize_frame(env.step(0)[0])\n",
        "\n",
        "    dummy_action = 0\n",
        "    dummy_reward = 0\n",
        "    dummy_done = False\n",
        "    for i in range(3):\n",
        "        agent.memory.add_experience(starting_frame, dummy_reward, dummy_action, dummy_done)\n",
        "\n",
        "def make_env(name, agent):\n",
        "    env = gym.make(name)\n",
        "    return env\n",
        "\n",
        "def take_step(name, env, agent, score, debug):\n",
        "    \n",
        "    #1 and 2: Update timesteps and save weights\n",
        "    agent.total_timesteps += 1\n",
        "    if agent.total_timesteps % 50000 == 0:\n",
        "      agent.model.save_weights('recent_weights.hdf5')\n",
        "      print('\\nWeights saved!')\n",
        "\n",
        "    #3: Take action\n",
        "    next_frame, next_frames_reward, next_frame_terminal, info = env.step(agent.memory.actions[-1])\n",
        "    \n",
        "    #4: Get next state\n",
        "    next_frame = resize_frame(next_frame)\n",
        "    new_state = [agent.memory.frames[-3], agent.memory.frames[-2], agent.memory.frames[-1], next_frame]\n",
        "    new_state = np.moveaxis(new_state,0,2)/255 #We have to do this to get it into keras's goofy format of [batch_size,rows,columns,channels]\n",
        "    new_state = np.expand_dims(new_state,0) #^^^\n",
        "    \n",
        "    #5: Get next action, using next state\n",
        "    next_action = agent.get_action(new_state)\n",
        "\n",
        "    #6: If game is over, return the score\n",
        "    if next_frame_terminal:\n",
        "        agent.memory.add_experience(next_frame, next_frames_reward, next_action, next_frame_terminal)\n",
        "        return (score + next_frames_reward),True\n",
        "\n",
        "    #7: Now we add the next experience to memory\n",
        "    agent.memory.add_experience(next_frame, next_frames_reward, next_action, next_frame_terminal)\n",
        "\n",
        "    #8: If we are trying to debug this then render\n",
        "    if debug:\n",
        "        env.render()\n",
        "\n",
        "    #9: If the threshold memory is satisfied, make the agent learn from memory\n",
        "    if len(agent.memory.frames) > agent.starting_mem_len:\n",
        "        agent.learn(debug)\n",
        "\n",
        "    return (score + next_frames_reward),False\n",
        "\n",
        "def play_episode(name, env, agent, debug = False):\n",
        "    initialize_new_game(name, env, agent)\n",
        "    done = False\n",
        "    score = 0\n",
        "    while True:\n",
        "        score,done = take_step(name,env,agent,score, debug)\n",
        "        if done:\n",
        "            break\n",
        "    return score"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JteeSBftLcI"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self,possible_actions,starting_mem_len,max_mem_len,starting_epsilon,learn_rate, starting_lives = 5, debug = False):\n",
        "        self.memory = Memory(max_mem_len)\n",
        "        self.possible_actions = possible_actions\n",
        "        self.epsilon = starting_epsilon\n",
        "        self.epsilon_decay = .9/100000\n",
        "        self.epsilon_min = .05\n",
        "        self.gamma = .95\n",
        "        self.learn_rate = learn_rate\n",
        "        self.model = self._build_model()\n",
        "        self.model_target = clone_model(self.model)\n",
        "        self.total_timesteps = 0\n",
        "        self.lives = starting_lives #this parameter does not apply to pong\n",
        "        self.starting_mem_len = starting_mem_len\n",
        "        self.learns = 0\n",
        "\n",
        "\n",
        "    def _build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Input((84,84,4)))\n",
        "        model.add(Conv2D(filters = 32,kernel_size = (8,8),strides = 4,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Conv2D(filters = 64,kernel_size = (4,4),strides = 2,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Conv2D(filters = 64,kernel_size = (3,3),strides = 1,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512,activation = 'relu', kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
        "        model.add(Dense(len(self.possible_actions), activation = 'linear'))\n",
        "        optimizer = Adam(self.learn_rate)\n",
        "        model.compile(optimizer, loss=tf.keras.losses.Huber())\n",
        "        model.summary()\n",
        "        print('\\nAgent Initialized\\n')\n",
        "        return model\n",
        "\n",
        "    def get_action(self,state):\n",
        "        \"\"\"Explore\"\"\"\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return random.sample(self.possible_actions,1)[0]\n",
        "\n",
        "        \"\"\"Do Best Acton\"\"\"\n",
        "        a_index = np.argmax(self.model.predict(state))\n",
        "        return self.possible_actions[a_index]\n",
        "\n",
        "    def _index_valid(self,index):\n",
        "        if self.memory.done_flags[index-3] or self.memory.done_flags[index-2] or self.memory.done_flags[index-1] or self.memory.done_flags[index]:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def learn(self,debug = False):\n",
        "        \"\"\"we want the output[a] to be R_(t+1) + Qmax_(t+1).\"\"\"\n",
        "        \"\"\"So target for taking action 1 should be [output[0], R_(t+1) + Qmax_(t+1), output[2]]\"\"\"\n",
        "\n",
        "        \"\"\"First we need 32 random valid indicies\"\"\"\n",
        "        states = []\n",
        "        next_states = []\n",
        "        actions_taken = []\n",
        "        next_rewards = []\n",
        "        next_done_flags = []\n",
        "\n",
        "        while len(states) < 32:\n",
        "            index = np.random.randint(4,len(self.memory.frames) - 1)\n",
        "            if self._index_valid(index):\n",
        "                state = [self.memory.frames[index-3], self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index]]\n",
        "                state = np.moveaxis(state,0,2)/255\n",
        "                next_state = [self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index], self.memory.frames[index+1]]\n",
        "                next_state = np.moveaxis(next_state,0,2)/255\n",
        "\n",
        "                states.append(state)\n",
        "                next_states.append(next_state)\n",
        "                actions_taken.append(self.memory.actions[index])\n",
        "                next_rewards.append(self.memory.rewards[index+1])\n",
        "                next_done_flags.append(self.memory.done_flags[index+1])\n",
        "\n",
        "        \"\"\"Now we get the ouputs from our model, and the target model. We need this for our target in the error function\"\"\"\n",
        "        labels = self.model.predict(np.array(states))\n",
        "        next_state_values = self.model_target.predict(np.array(next_states))\n",
        "        \n",
        "        \"\"\"Now we define our labels, or what the output should have been\n",
        "           We want the output[action_taken] to be R_(t+1) + Qmax_(t+1) \"\"\"\n",
        "        for i in range(32):\n",
        "            action = self.possible_actions.index(actions_taken[i])\n",
        "            labels[i][action] = next_rewards[i] + (not next_done_flags[i]) * self.gamma * max(next_state_values[i])\n",
        "\n",
        "        \"\"\"Train our model using the states and outputs generated\"\"\"\n",
        "        self.model.fit(np.array(states),labels,batch_size = 32, epochs = 1, verbose = 0)\n",
        "\n",
        "        \"\"\"Decrease epsilon and update how many times our agent has learned\"\"\"\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon -= self.epsilon_decay\n",
        "        self.learns += 1\n",
        "        \n",
        "        \"\"\"Every 10000 learned, copy our model weights to our target model\"\"\"\n",
        "        if self.learns % 10000 == 0:\n",
        "            self.model_target.set_weights(self.model.get_weights())\n",
        "            print('\\nTarget model updated')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wd27jWHtea_",
        "outputId": "ea2050fb-2184-4100-f0fa-0083b8c36420"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "name = 'PongDeterministic-v4'\n",
        "\n",
        "agent = Agent(possible_actions=[0,2,3],starting_mem_len=50000,max_mem_len=750000,starting_epsilon = 1, learn_rate = .00025)\n",
        "env = make_env(name,agent)\n",
        "\n",
        "last_100_avg = [-21]\n",
        "scores = deque(maxlen = 100)\n",
        "max_score = -21\n",
        "\n",
        "\"\"\" If testing:\n",
        "agent.model.load_weights('recent_weights.hdf5')\n",
        "agent.model_target.load_weights('recent_weights.hdf5')\n",
        "agent.epsilon = 0.0\n",
        "\"\"\"\n",
        "\n",
        "env.reset()\n",
        "\n",
        "for i in range(1000000):\n",
        "    timesteps = agent.total_timesteps\n",
        "    timee = time.time()\n",
        "    score = play_episode(name, env, agent, debug = False) #set debug to true for rendering\n",
        "    scores.append(score)\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "\n",
        "    print('\\nEpisode: ' + str(i))\n",
        "    print('Steps: ' + str(agent.total_timesteps - timesteps))\n",
        "    print('Duration: ' + str(time.time() - timee))\n",
        "    print('Score: ' + str(score))\n",
        "    print('Max Score: ' + str(max_score))\n",
        "    print('Epsilon: ' + str(agent.epsilon))\n",
        "\n",
        "    if i%100==0 and i!=0:\n",
        "        last_100_avg.append(sum(scores)/len(scores))\n",
        "        plt.plot(np.arange(0,i+1,100),last_100_avg)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,685,667\n",
            "Trainable params: 1,685,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Agent Initialized\n",
            "\n",
            "\n",
            "Episode: 0\n",
            "Steps: 823\n",
            "Duration: 1.3435111045837402\n",
            "Score: -21.0\n",
            "Max Score: -21\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 1\n",
            "Steps: 823\n",
            "Duration: 1.3666894435882568\n",
            "Score: -21.0\n",
            "Max Score: -21\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 2\n",
            "Steps: 978\n",
            "Duration: 1.604710578918457\n",
            "Score: -20.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 3\n",
            "Steps: 918\n",
            "Duration: 1.4789021015167236\n",
            "Score: -20.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 4\n",
            "Steps: 1125\n",
            "Duration: 1.8736979961395264\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 5\n",
            "Steps: 978\n",
            "Duration: 1.5733559131622314\n",
            "Score: -20.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 6\n",
            "Steps: 883\n",
            "Duration: 1.4460029602050781\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 7\n",
            "Steps: 885\n",
            "Duration: 1.473097324371338\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 8\n",
            "Steps: 1067\n",
            "Duration: 1.7146265506744385\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 9\n",
            "Steps: 1005\n",
            "Duration: 1.6650991439819336\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 10\n",
            "Steps: 1009\n",
            "Duration: 1.6781129837036133\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 11\n",
            "Steps: 1128\n",
            "Duration: 1.870370626449585\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 12\n",
            "Steps: 945\n",
            "Duration: 1.6304690837860107\n",
            "Score: -21.0\n",
            "Max Score: -20.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 13\n",
            "Steps: 1073\n",
            "Duration: 1.8137786388397217\n",
            "Score: -19.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 14\n",
            "Steps: 1003\n",
            "Duration: 1.721203327178955\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 15\n",
            "Steps: 1125\n",
            "Duration: 1.8864977359771729\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 16\n",
            "Steps: 1004\n",
            "Duration: 1.744375467300415\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 17\n",
            "Steps: 945\n",
            "Duration: 1.6115496158599854\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 18\n",
            "Steps: 1129\n",
            "Duration: 1.8868341445922852\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 19\n",
            "Steps: 919\n",
            "Duration: 1.5068130493164062\n",
            "Score: -20.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 20\n",
            "Steps: 922\n",
            "Duration: 1.5636131763458252\n",
            "Score: -20.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 21\n",
            "Steps: 885\n",
            "Duration: 1.4785692691802979\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 22\n",
            "Steps: 885\n",
            "Duration: 1.4797914028167725\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 23\n",
            "Steps: 943\n",
            "Duration: 1.6278269290924072\n",
            "Score: -21.0\n",
            "Max Score: -19.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 24\n",
            "Steps: 1172\n",
            "Duration: 1.9667494297027588\n",
            "Score: -18.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 25\n",
            "Steps: 1245\n",
            "Duration: 1.9957776069641113\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 26\n",
            "Steps: 1014\n",
            "Duration: 1.6272327899932861\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 27\n",
            "Steps: 1136\n",
            "Duration: 1.8509817123413086\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 28\n",
            "Steps: 1013\n",
            "Duration: 1.6212761402130127\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 29\n",
            "Steps: 883\n",
            "Duration: 1.4243760108947754\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 30\n",
            "Steps: 883\n",
            "Duration: 1.4383232593536377\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 31\n",
            "Steps: 945\n",
            "Duration: 1.510019302368164\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 32\n",
            "Steps: 883\n",
            "Duration: 1.4221036434173584\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 33\n",
            "Steps: 1064\n",
            "Duration: 1.744215726852417\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 34\n",
            "Steps: 823\n",
            "Duration: 1.2869713306427002\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 35\n",
            "Steps: 883\n",
            "Duration: 1.3845398426055908\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 36\n",
            "Steps: 1005\n",
            "Duration: 1.5305438041687012\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 37\n",
            "Steps: 885\n",
            "Duration: 1.3526897430419922\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 38\n",
            "Steps: 1076\n",
            "Duration: 1.6871228218078613\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 39\n",
            "Steps: 1171\n",
            "Duration: 1.8324780464172363\n",
            "Score: -18.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 40\n",
            "Steps: 823\n",
            "Duration: 1.2667934894561768\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 41\n",
            "Steps: 883\n",
            "Duration: 1.354457139968872\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 42\n",
            "Steps: 1041\n",
            "Duration: 1.6507148742675781\n",
            "Score: -20.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 43\n",
            "Steps: 943\n",
            "Duration: 1.458606243133545\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 44\n",
            "Steps: 887\n",
            "Duration: 1.3549377918243408\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 45\n",
            "Steps: 1041\n",
            "Duration: 1.610701560974121\n",
            "Score: -20.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 46\n",
            "Steps: 920\n",
            "Duration: 1.4442002773284912\n",
            "Score: -20.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 47\n",
            "Steps: 1076\n",
            "Duration: 1.6842155456542969\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 48\n",
            "Steps: 1125\n",
            "Duration: 1.7558238506317139\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Episode: 49\n",
            "Steps: 1254\n",
            "Duration: 1.9579596519470215\n",
            "Score: -19.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 1\n",
            "\n",
            "Weights saved!\n",
            "\n",
            "Episode: 50\n",
            "Steps: 823\n",
            "Duration: 94.80840611457825\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 0.9959589999999835\n",
            "\n",
            "Episode: 51\n",
            "Steps: 823\n",
            "Duration: 173.0456998348236\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 0.9885609999999533\n",
            "\n",
            "Episode: 52\n",
            "Steps: 823\n",
            "Duration: 178.49530696868896\n",
            "Score: -21.0\n",
            "Max Score: -18.0\n",
            "Epsilon: 0.9811629999999231\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}