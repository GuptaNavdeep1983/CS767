{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUAr51sEZS6rer5+IYAASD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuptaNavdeep1983/CS767/blob/main/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA3_HENeBQVT"
      },
      "source": [
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWw7ta9INmAc"
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0) # only difference\n",
        "def sigmoid(x):\n",
        "  output = [0] * len(x)\n",
        "  for index, item in enumerate(x): \n",
        "    output[index] = 1.0 if item > 0.0 else 0.0 \n",
        "  return output\n",
        "\n",
        "def relu(x):\n",
        "  output = [0] * len(x)\n",
        "  for index, item in enumerate(x): \n",
        "    output[index] = item if item > 0.0 else 0.0 \n",
        "  return output"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vkOKqUPFY0t"
      },
      "source": [
        "class Layer():\n",
        "  def __init__(self, name, units, input_dim):\n",
        "    self.name = name\n",
        "    self.w = [[random.uniform(-2,2) for _ in range(input_dim)] for _ in range(units)]\n",
        "    self.b = [0 for _ in range(units)]\n",
        "    self.output = [bias for bias in self.b]\n",
        "  def calculate_output(self, inputs, activation=sigmoid):\n",
        "    self.output = [bias for bias in self.b]\n",
        "    for row_index, col in enumerate(self.w):\n",
        "      for col_index, weight in enumerate(col):\n",
        "        self.output[row_index] += weight * inputs[col_index]\n",
        "    self.output = activation(self.output)\n",
        "    return self.output \n",
        "  def update_weights(self, error, inputs, learning_rate):\n",
        "    error_out = 0\n",
        "    for row_index, col in enumerate(self.w):\n",
        "      for col_index, weight in enumerate(col):\n",
        "        self.w[row_index][col_index] = self.w[row_index][col_index] + (learning_rate * error * inputs[col_index])\n",
        "        self.b[row_index] = self.b[row_index] + (learning_rate * error)\n",
        "    for input_idx, input in enumerate(inputs):\n",
        "      error_out += sum([error * weight[input_idx] for weight_idx, weight in enumerate(self.w)])\n",
        "    return error_out"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLEqMj-uWIHC"
      },
      "source": [
        "def reset_layers():\n",
        "  layer1 = Layer(\"Hidden1\", 3, 2)\n",
        "  layer2 = Layer(\"Output\", 3, 3)\n",
        "  layers = [layer1, layer2]\n",
        "  return layers"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHMYuFAERXRP"
      },
      "source": [
        "iris = load_iris()\n",
        "\n",
        "iris_columns = ['sepal_len', 'sepal_width', 'petal_length', 'petal_width', 'target']\n",
        "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris_columns)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J359lR1SRnyu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# X = df[['sepal_len', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "X = df[['sepal_width', 'petal_length']]\n",
        "y = df[['target']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 10)\n",
        "\n",
        "\n",
        "scaler_training = StandardScaler() \n",
        "scaler_training.fit(X_train)\n",
        "scaled_values_training = scaler_training.transform(X_train)\n",
        "scaled_values_testing = scaler_training.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(scaled_values_training, columns=[*X_train.columns.values])\n",
        "X_test = pd.DataFrame(scaled_values_testing, columns=[*X_test.columns.values])\n",
        "\n",
        "\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBdWTT0pSJU_"
      },
      "source": [
        "import random\n",
        "random.seed(34)\n",
        "selected_rows = random.sample(range(0,119),   5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmdWwns5U23f",
        "outputId": "311efb08-244d-4b81-9553-ae4300913cd8"
      },
      "source": [
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit([0,1,2])\n",
        "lb.transform([0])\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRmzSqyQUEeN"
      },
      "source": [
        "def categorical_cross_entropy(actual, predicted):\n",
        "\tsum_score = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\t\tsum_score += actual[i] * math.log(1e-15 + predicted[i])\n",
        "\tmean_sum_score = (1.0 / len(actual)) * sum_score\n",
        "\treturn -mean_sum_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzwEWlmlRvLb",
        "outputId": "a98e85bb-f843-4ef1-be9f-fb6d83a88bdc"
      },
      "source": [
        "def train_weights_using_mini_batch_gradient_descent(X_train, y_train, num_epochs, learning_rate, layers):\n",
        "  # weights for all the features \n",
        "  index = 0;\n",
        "  error = 0\n",
        "  mini_batch = X_train.loc[selected_rows, :]\n",
        "  y_train = y_train.loc[selected_rows, :]\n",
        "  while index < num_epochs:\n",
        "    print(\"Iteration %d\"%(index+1))\n",
        "    for rowIndex, row in mini_batch.iterrows():\n",
        "      # print(y_train.loc[rowIndex,'target'])\n",
        "      output = row\n",
        "      for layer_idx, layer in enumerate(layers):\n",
        "        if layer_idx == len(layers) - 1:\n",
        "          output = layer.calculate_output(output, softmax)\n",
        "        else:\n",
        "          output = layer.calculate_output(output, relu)\n",
        "      # print(output)\n",
        "      # print(lb.transform([y_train.loc[rowIndex,'target']]))\n",
        "      # print(categorical_cross_entropy(lb.transform([y_train.loc[rowIndex,'target']])[0], output))\n",
        "      error = log_loss([y_train.loc[rowIndex,'target']], [output], labels=[0.0, 1.0, 2.0])\n",
        "      print(\"Entropy based loss: %f\"% (error))\n",
        "      if error != 0:\n",
        "        layer1_error = layers[1].update_weights(error, layers[0].output, learning_rate)\n",
        "        layers[0].update_weights(layer1_error, row, learning_rate)\n",
        "      print(\"New Weights of output layer\", layers[1].w)\n",
        "      print(\"New Weights of hidden layer\", layers[0].w)\n",
        "    # for layer_idx, layer in enumerate(layers):\n",
        "    #   layer.update_weights()\n",
        "    index = index + 1\n",
        "  # df_plot = pd.DataFrame(df_plot, columns=['mse', 'epoch'])\n",
        "  return\n",
        "\n",
        "layers = reset_layers()\n",
        "print(\"Creating model using training data\")\n",
        "train_weights_using_mini_batch_gradient_descent(X_train, y_train, 30, 0.01, layers)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model using training data\n",
            "Iteration 1\n",
            "Entropy based loss: 1.069691\n",
            "New Weights of output layer [[0.935065127354219, 0.4514718502417332, 1.3184982813309336], [-1.7722032810881396, 1.667270311591643, 0.3857743145198533], [0.5812496134286915, 1.1841164152291896, -1.6973198750034157]]\n",
            "New Weights of hidden layer [[0.8125920418298592, 1.9288376140209293], [0.3383525543447529, 0.055146235745461035], [-0.33026606056999946, 1.6250216191531472]]\n",
            "Entropy based loss: 4.833482\n",
            "New Weights of output layer [[0.98262776925118, 0.4514718502417332, 1.3899782104505212], [-1.7246406391911786, 1.667270311591643, 0.4572542436394409], [0.6288122553256525, 1.1841164152291896, -1.6258399458838282]]\n",
            "New Weights of hidden layer [[0.7086954789637538, 2.0511351739689463], [0.2344559914786476, 0.17744379569347796], [-0.4341626234361048, 1.7473191791011642]]\n",
            "Entropy based loss: 1.344669\n",
            "New Weights of output layer [[0.98262776925118, 0.45624607771663567, 1.3899782104505212], [-1.7246406391911786, 1.6720445390665455, 0.4572542436394409], [0.6288122553256525, 1.1888906427040922, -1.6258399458838282]]\n",
            "New Weights of hidden layer [[0.7435790473240168, 1.9946524639398309], [0.26933955983891056, 0.12096108566436264], [-0.3992790550758418, 1.6908364690720488]]\n",
            "Entropy based loss: 6.248704\n",
            "New Weights of output layer [[1.0762457418400566, 0.4816906395594937, 1.5145163471867797], [-1.631022666602302, 1.6974891009094035, 0.5817923803756994], [0.722430227914529, 1.2143352045469502, -1.5013018091475696]]\n",
            "New Weights of hidden layer [[0.579921231842644, 2.1872955211080316], [0.10568174435753772, 0.3136041428325633], [-0.5629368705572146, 1.8834795262402495]]\n",
            "Entropy based loss: 1.670375\n",
            "New Weights of output layer [[1.0762457418400566, 0.4945755295750493, 1.5145163471867797], [-1.631022666602302, 1.7103739909249591, 0.5817923803756994], [0.722430227914529, 1.2272200945625058, -1.5013018091475696]]\n",
            "New Weights of hidden layer [[0.7140070158166052, 2.08955024643416], [0.23976752833149892, 0.21585886815869187], [-0.42885108658325344, 1.785734251566378]]\n",
            "Iteration 2\n",
            "Entropy based loss: 1.264113\n",
            "New Weights of output layer [[1.076989904440344, 0.5043875652730857, 1.5376867328302284], [-1.6302785040020147, 1.7201860266229956, 0.604962766019148], [0.7231743905148165, 1.2370321302605423, -1.478131423504121]]\n",
            "New Weights of hidden layer [[0.6295511344848211, 2.090135531778257], [0.1553116469997149, 0.21644415350278864], [-0.5133069679150375, 1.786319536910475]]\n",
            "Entropy based loss: 8.644911\n",
            "New Weights of output layer [[1.2852498555297243, 0.6183314635176576, 1.788723886993095], [-1.4220185529126343, 1.8341299248675675, 0.8559999201820147], [0.9314343416041968, 1.3509760285051142, -1.2270942693412543]]\n",
            "New Weights of hidden layer [[0.30183182968279887, 2.475896814149062], [-0.17240765780230738, 0.6022054358735935], [-0.8410262727170598, 2.17208081928128]]\n",
            "Entropy based loss: 2.252157\n",
            "New Weights of output layer [[1.2852498555297243, 0.6504567917456694, 1.788723886993095], [-1.4220185529126343, 1.8662552530955794, 0.8559999201820147], [0.9314343416041968, 1.383101356733126, -1.2270942693412543]]\n",
            "New Weights of hidden layer [[0.4060845817256975, 2.3070930409065267], [-0.06815490575940875, 0.4334016626310583], [-0.7367735206741611, 2.0032770460387446]]\n",
            "Entropy based loss: 12.908724\n",
            "New Weights of output layer [[1.8049831870593458, 1.0293558438896242, 2.3723328408295763], [-0.9022852213830127, 2.2451543052395344, 1.4396088740184958], [1.4511676731338183, 1.7620004088770809, -0.6434853155047732]]\n",
            "New Weights of hidden layer [[-0.45283432908231736, 3.318134061776501], [-0.9270738165674236, 1.4444426835010327], [-1.5956924314821759, 3.014318066908719]]\n",
            "Entropy based loss: 2.329400\n",
            "New Weights of output layer [[1.8049831870593458, 1.0644779933130903, 2.3723328408295763], [-0.9022852213830127, 2.2802764546630003, 1.4396088740184958], [1.4511676731338183, 1.797122558300547, -0.6434853155047732]]\n",
            "New Weights of hidden layer [[0.02253025848081669, 2.971604841418485], [-0.45170922900428956, 1.0979134631430165], [-1.1203278439190418, 2.6677888465507027]]\n",
            "Iteration 3\n",
            "Entropy based loss: 14.820163\n",
            "New Weights of output layer [[2.6631620011364836, 2.0289664138260766, 3.493431406855257], [-0.044106407305875006, 3.2447648751759868, 2.560707440044177], [2.309346487210956, 2.7616109788135335, 0.477613250520908]]\n",
            "New Weights of hidden layer [[-4.470776116219558, 3.002743778413498], [-4.945015603704665, 1.1290524001380293], [-5.613634218619417, 2.6989277835457157]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[8.40240909331049, 7.391395172526533, 9.403585082655425], [5.695140684868132, 8.607193633876442, 8.470861115844345], [8.048593579384963, 8.12403973751399, 6.387766926321076]]\n",
            "New Weights of hidden layer [[-19.82188874306659, 21.072673764163376], [-20.296128230551698, 19.19898238588791], [-20.96474684546645, 20.768857769295597]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[8.40240909331049, 7.391395172526534, 9.403585082655425], [5.695140684868132, 8.607193633876442, 8.470861115844345], [8.048593579384963, 8.12403973751399, 6.387766926321076]]\n",
            "New Weights of hidden layer [[-19.82188874306659, 21.072673764163373], [-20.296128230551698, 19.198982385887906], [-20.96474684546645, 20.768857769295593]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[38.93998799478326, 37.552155740525755, 40.11207056775436], [36.232719586340906, 38.76795420187566, 39.17934660094328], [38.58617248085773, 38.28480030551321, 37.09625241142001]]\n",
            "New Weights of hidden layer [[-94.8572577665959, 109.39746804251563], [-95.331497254081, 107.52377666424016], [-96.00011586899575, 109.09365204764785]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[38.93998799478326, 37.552155740525755, 40.11207056775436], [36.232719586340906, 38.76795420187566, 39.17934660094328], [38.58617248085773, 38.28480030551321, 37.09625241142001]]\n",
            "New Weights of hidden layer [[-87.60947741370268, 104.11401247867292], [-88.08371690118778, 102.24032110039747], [-88.75233551610253, 103.81019648380516]]\n",
            "Iteration 4\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[192.07941740089635, 190.9393424516035, 193.86424129940374], [189.37214899245402, 192.15514091295339, 192.93151733259268], [191.72560188697082, 191.67198701659095, 190.8484231430694]]\n",
            "New Weights of hidden layer [[-1014.4878692497125, 110.53734653128244], [-1014.9621087371976, 108.66365515300699], [-1015.6307273521123, 110.23353053641468]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[958.5964315779265, 957.0795382951602, 960.5521620600601], [955.8891631694842, 958.2953367565101, 959.6194380932491], [958.242616064001, 957.8121828601477, 957.5363439037258]]\n",
            "New Weights of hidden layer [[-2891.4248089722505, 2319.896362576749], [-2891.8990484597357, 2318.0226711984737], [-2892.56766707465, 2319.5925465818814]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[958.5964315779265, 957.0795382951602, 960.5521620600601], [955.8891631694842, 958.2953367565101, 959.6194380932491], [958.242616064001, 957.8121828601477, 957.5363439037258]]\n",
            "New Weights of hidden layer [[-2891.4248089722505, 2319.896362576749], [-2891.8990484597357, 2318.0226711984737], [-2892.56766707465, 2319.5925465818814]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[4757.135042350405, 4755.241330734166, 4759.261679416165], [4754.427773941963, 4756.457129195516, 4758.328955449354], [4756.78122683648, 4755.973975299154, 4756.24586125983]]\n",
            "New Weights of hidden layer [[-12209.015855020818, 13287.714912972519], [-12209.490094508303, 13285.841221594243], [-12210.158713123217, 13287.41109697765]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4757.135042350405, 4755.241330734166, 4759.261679416165], [4754.427773941963, 4756.457129195516, 4758.328955449354], [4756.78122683648, 4755.973975299154, 4756.24586125983]]\n",
            "New Weights of hidden layer [[-11309.01557250514, 12631.636600911186], [-11309.489811992626, 12629.76290953291], [-11310.15843060754, 12631.332784916318]]\n",
            "Iteration 5\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[23992.20695685119, 23990.561002539922, 23994.94633524249], [23989.49968844275, 23991.776801001273, 23994.013611275677], [23991.853141337266, 23991.29364710491, 23991.930517086155]]\n",
            "New Weights of hidden layer [[-127292.14361087819, 13435.408036753292], [-127292.61785036567, 13433.534345375016], [-127293.28646898059, 13435.104220758423]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[119770.39529195511, 119768.37251931037, 119773.30557693006], [119767.68802354667, 119769.58831777173, 119772.37285296324], [119770.04147644118, 119769.10516387536, 119770.28975877372]]\n",
            "New Weights of hidden layer [[-361904.5287823481, 289599.71461763605], [-361905.0030218356, 289597.8409262578], [-361905.6716404505, 289599.4108016412]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[119770.39529195511, 119768.37251931037, 119773.30557693006], [119767.68802354667, 119769.58831777173, 119772.37285296324], [119770.04147644118, 119769.10516387536, 119770.28975877372]]\n",
            "New Weights of hidden layer [[-361904.5287823481, 289599.71461763605], [-361905.0030218356, 289597.8409262578], [-361905.6716404505, 289599.4108016412]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[594543.6386094728, 594541.2390184945, 594546.7198010313], [594540.9313410644, 594542.4548169558, 594545.7870770645], [594543.2847939589, 594541.9716630594, 594543.703982875]]\n",
            "New Weights of hidden layer [[-1526528.9968141662, 1660489.4415434767], [-1526529.4710536536, 1660487.5678520985], [-1526530.1396722686, 1660489.1377274818]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[594543.6386094728, 594541.2390184945, 594546.7198010313], [594540.9313410644, 594542.4548169558, 594545.7870770645], [594543.2847939589, 594541.9716630594, 594543.703982875]]\n",
            "New Weights of hidden layer [[-1414036.1491378546, 1578484.8921491697], [-1414036.623377342, 1578483.0184577915], [-1414037.291995957, 1578484.5883331748]]\n",
            "Iteration 6\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[2999012.9687312623, 2999010.816897589, 2999016.662664147], [2999010.261462854, 2999012.0326960506, 2999015.72994018], [2999012.6149157486, 2999011.549542154, 2999013.646845991]]\n",
            "New Weights of hidden layer [[-15911984.128720837, 1678956.7164688082], [-15911984.602960324, 1678954.84277743], [-15911985.27157894, 1678956.4126528134]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[14971160.341529055, 14971157.812877048, 14971164.206368525], [14971157.634260647, 14971159.028675511, 14971163.273644557], [14971159.987713542, 14971158.545521613, 14971161.190550368]]\n",
            "New Weights of hidden layer [[-45238324.88642275, 36199250.91997489], [-45238325.36066224, 36199249.04628351], [-45238326.029280856, 36199250.616158895]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[14971160.341529055, 14971157.812877048, 14971164.206368525], [14971157.634260647, 14971159.028675511, 14971163.273644557], [14971159.987713542, 14971158.545521613, 14971161.190550368]]\n",
            "New Weights of hidden layer [[-45238324.88642275, 36199250.91997489], [-45238325.36066224, 36199249.04628351], [-45238326.029280856, 36199250.616158895]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[74317354.5694194, 74317351.66394906, 74317358.60516545], [74317351.862151, 74317352.87974752, 74317357.67244148], [74317354.21560389, 74317352.39659363, 74317355.58934729]]\n",
            "New Weights of hidden layer [[-190815289.27518952, 207559178.8930466], [-190815289.749429, 207559177.0193552], [-190815290.4180476, 207559178.5892306]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[74317354.5694194, 74317351.66394906, 74317358.60516545], [74317351.862151, 74317352.87974752, 74317357.67244148], [74317354.21560389, 74317352.39659363, 74317355.58934729]]\n",
            "New Weights of hidden layer [[-176753788.9979019, 197308687.25854856], [-176753789.47214136, 197308685.38485718], [-176753790.14075997, 197308686.95473257]]\n",
            "Iteration 7\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[374874049.51161885, 374874046.8539058, 374874054.1601062], [374874046.8043505, 374874048.06970423, 374874053.22738224], [374874049.15780336, 374874047.58655035, 374874051.14428806]]\n",
            "New Weights of hidden layer [[-1988984884.5006804, 209867579.35213012], [-1988984884.9749198, 209867577.47843874], [-1988984885.6435385, 209867579.04831412]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[1871382017.0744975, 1871382014.039966, 1871382021.8938913], [1871382014.367229, 1871382015.2557647, 1871382020.9611673], [1871382016.720682, 1871382014.7726107, 1871382018.8780732]]\n",
            "New Weights of hidden layer [[-5654751992.613383, 4524874354.288836], [-5654751993.087623, 4524874352.415144], [-5654751993.756241, 4524874353.98502]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[1871382017.0744975, 1871382014.039966, 1871382021.8938913], [1871382014.367229, 1871382015.2557647, 1871382020.9611673], [1871382016.720682, 1871382014.7726107, 1871382018.8780732]]\n",
            "New Weights of hidden layer [[-5654751992.613383, 4524874354.288836], [-5654751993.087623, 4524874352.415144], [-5654751993.756241, 4524874353.98502]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[9289604670.230387, 9289604666.819038, 9289604675.220688], [9289604667.523117, 9289604668.034836, 9289604674.287964], [9289604669.87657, 9289604667.551682, 9289604672.204868]]\n",
            "New Weights of hidden layer [[-23851745944.714474, 25944716333.07293], [-23851745945.188713, 25944716331.19924], [-23851745945.85733, 25944716332.769115]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9289604670.230387, 9289604666.819038, 9289604675.220688], [9289604667.523117, 9289604668.034836, 9289604674.287964], [9289604669.87657, 9289604667.551682, 9289604672.204868]]\n",
            "New Weights of hidden layer [[-22094070638.20138, 24663413792.782997], [-22094070638.67562, 24663413790.90931], [-22094070639.34424, 24663413792.479183]]\n",
            "Iteration 8\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[46858930516.18598, 46858930513.02239, 46858930521.789024], [46858930513.478714, 46858930514.23819, 46858930520.8563], [46858930515.83217, 46858930513.755035, 46858930518.77321]]\n",
            "New Weights of hidden layer [[-248621383135.7972, 26233264393.496284], [-248621383136.27145, 26233264391.622597], [-248621383136.94006, 26233264393.19247]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[233921126055.30093, 233921126051.76056, 233921126061.07492], [233921126052.5937, 233921126052.97635, 233921126060.14218], [233921126054.94714, 233921126052.4932, 233921126058.05908]]\n",
            "New Weights of hidden layer [[-706839086388.3134, 565605361861.1118], [-706839086388.7876, 565605361859.2382], [-706839086389.4562, 565605361860.808]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[233921126055.30093, 233921126051.76056, 233921126061.07492], [233921126052.5937, 233921126052.97635, 233921126060.14218], [233921126054.94714, 233921126052.4932, 233921126058.05908]]\n",
            "New Weights of hidden layer [[-706839086388.3134, 565605361861.1118], [-706839086388.7876, 565605361859.2382], [-706839086389.4562, 565605361860.808]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[1161192511792.0222, 1161192511788.105, 1161192511797.967], [1161192511789.315, 1161192511789.3208, 1161192511797.0344], [1161192511791.6685, 1161192511788.8376, 1161192511794.9512]]\n",
            "New Weights of hidden layer [[-2981447518553.651, 3243066996944.2944], [-2981447518554.125, 3243066996942.421], [-2981447518554.7935, 3243066996943.9907]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1161192511792.0222, 1161192511788.105, 1161192511797.967], [1161192511789.315, 1161192511789.3208, 1161192511797.0344], [1161192511791.6685, 1161192511788.8376, 1161192511794.9512]]\n",
            "New Weights of hidden layer [[-2761739632529.88, 3082905292765.576], [-2761739632530.3545, 3082905292763.7026], [-2761739632531.0225, 3082905292765.2725]]\n",
            "Iteration 9\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[5857325597982.684, 5857325597979.016, 5857325597989.241], [5857325597979.977, 5857325597980.23, 5857325597988.309], [5857325597982.33, 5857325597979.748, 5857325597986.226]]\n",
            "New Weights of hidden layer [[-31077456861053.953, 3279135253783.181], [-31077456861054.43, 3279135253781.3076], [-31077456861055.098, 3279135253782.8774]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[29239937498327.55, 29239937498323.504, 29239937498334.28], [29239937498324.844, 29239937498324.72, 29239937498333.348], [29239937498327.195, 29239937498324.234, 29239937498331.266]]\n",
            "New Weights of hidden layer [[-88354271613360.78, 70700178766348.88], [-88354271613361.27, 70700178766347.0], [-88354271613361.94, 70700178766348.58]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[29239937498327.55, 29239937498323.504, 29239937498334.28], [29239937498324.844, 29239937498324.72, 29239937498333.348], [29239937498327.195, 29239937498324.234, 29239937498331.266]]\n",
            "New Weights of hidden layer [[-88354271613360.78, 70700178766348.88], [-88354271613361.27, 70700178766347.0], [-88354271613361.94, 70700178766348.58]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[145148054991238.28, 145148054991233.84, 145148054991245.2], [145148054991235.56, 145148054991235.06, 145148054991244.25], [145148054991237.94, 145148054991234.56, 145148054991242.16]]\n",
            "New Weights of hidden layer [[-372678349182481.4, 405380556653209.9], [-372678349182481.9, 405380556653208.0], [-372678349182482.56, 405380556653209.56]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[145148054991238.28, 145148054991233.84, 145148054991245.2], [145148054991235.56, 145148054991235.06, 145148054991244.25], [145148054991237.94, 145148054991234.56, 145148054991242.16]]\n",
            "New Weights of hidden layer [[-345215054337969.25, 385360482798492.7], [-345215054337969.75, 385360482798490.8], [-345215054337970.44, 385360482798492.4]]\n",
            "Iteration 10\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[732160610204128.5, 732160610204124.5, 732160610204136.2], [732160610204125.8, 732160610204125.8, 732160610204135.2], [732160610204128.2, 732160610204125.2, 732160610204133.1]]\n",
            "New Weights of hidden layer [[-3884655103827879.0, 409889057417676.3], [-3884655103827879.0, 409889057417674.44], [-3884655103827880.0, 409889057417676.0]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[3654966780142087.5, 3654966780142083.5, 3654966780142095.0], [3654966780142085.0, 3654966780142085.0, 3654966780142094.0], [3654966780142087.0, 3654966780142084.0, 3654966780142092.0]]\n",
            "New Weights of hidden layer [[-1.1044207178930824e+16, 8837460913035827.0], [-1.1044207178930824e+16, 8837460913035825.0], [-1.1044207178930824e+16, 8837460913035827.0]]\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[3654966780142087.5, 3654966780142083.5, 3654966780142095.0], [3654966780142085.0, 3654966780142085.0, 3654966780142094.0], [3654966780142087.0, 3654966780142084.0, 3654966780142092.0]]\n",
            "New Weights of hidden layer [[-1.1044207178930824e+16, 8837460913035826.0], [-1.1044207178930824e+16, 8837460913035824.0], [-1.1044207178930824e+16, 8837460913035826.0]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[1.8143380751944132e+16, 1.814338075194413e+16, 1.814338075194414e+16], [1.8143380751944132e+16, 1.8143380751944132e+16, 1.814338075194414e+16], [1.8143380751944132e+16, 1.814338075194413e+16, 1.8143380751944136e+16]]\n",
            "New Weights of hidden layer [[-4.658446982036435e+16, 5.0672217338620696e+16], [-4.658446982036435e+16, 5.0672217338620696e+16], [-4.658446982036435e+16, 5.0672217338620696e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.8143380751944132e+16, 1.814338075194413e+16, 1.814338075194414e+16], [1.8143380751944132e+16, 1.8143380751944132e+16, 1.814338075194414e+16], [1.8143380751944132e+16, 1.814338075194413e+16, 1.8143380751944136e+16]]\n",
            "New Weights of hidden layer [[-4.315158182818998e+16, 4.816972550261158e+16], [-4.315158182818998e+16, 4.816972550261158e+16], [-4.315158182818998e+16, 4.816972550261158e+16]]\n",
            "Iteration 11\n",
            "Entropy based loss: 0.000000\n",
            "New Weights of output layer [[1.8143380751944136e+16, 1.8143380751944132e+16, 1.8143380751944144e+16], [1.8143380751944136e+16, 1.8143380751944136e+16, 1.8143380751944144e+16], [1.8143380751944136e+16, 1.8143380751944132e+16, 1.814338075194414e+16]]\n",
            "New Weights of hidden layer [[-4.315158182818999e+16, 4.816972550261158e+16], [-4.315158182818999e+16, 4.816972550261158e+16], [-4.315158182818999e+16, 4.816972550261158e+16]]\n",
            "Entropy based loss: 34.538776\n",
            "New Weights of output layer [[8.989476674789587e+16, 8.989476674789587e+16, 8.989476674789589e+16], [8.989476674789587e+16, 8.989476674789587e+16, 8.989476674789589e+16], [8.989476674789587e+16, 8.989476674789587e+16, 8.989476674789589e+16]]\n",
            "New Weights of hidden layer [[-2.192424473615212e+17, 2.5544783547834e+17], [-2.192424473615212e+17, 2.5544783547834e+17], [-2.192424473615212e+17, 2.5544783547834e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.236000684571582e+16, 9.236000684571582e+16, 9.236000684571584e+16], [9.236000684571582e+16, 9.236000684571582e+16, 9.236000684571584e+16], [9.236000684571582e+16, 9.236000684571582e+16, 9.236000684571584e+16]]\n",
            "New Weights of hidden layer [[-2.1232622930755763e+17, 2.4424924665262928e+17], [-2.1232622930755763e+17, 2.4424924665262928e+17], [-2.1232622930755763e+17, 2.4424924665262928e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17], [1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17], [1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17]]\n",
            "New Weights of hidden layer [[-2.187907438051609e+17, 2.5185868364934998e+17], [-2.187907438051609e+17, 2.5185868364934998e+17], [-2.187907438051609e+17, 2.5185868364934998e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17], [1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17], [1.0375188376320813e+17, 1.0375188376320813e+17, 1.0375188376320814e+17]]\n",
            "New Weights of hidden layer [[-1.9915997042253078e+17, 2.3754832740220054e+17], [-1.9915997042253078e+17, 2.3754832740220054e+17], [-1.9915997042253078e+17, 2.3754832740220054e+17]]\n",
            "Iteration 12\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.1556502654381795e+17, 1.1556502654381795e+17, 1.1556502654381797e+17], [1.1556502654381795e+17, 1.1556502654381795e+17, 1.1556502654381797e+17], [1.1556502654381795e+17, 1.1556502654381795e+17, 1.1556502654381797e+17]]\n",
            "New Weights of hidden layer [[-2.1693016276216163e+17, 2.376714761157556e+17], [-2.1693016276216163e+17, 2.376714761157556e+17], [-2.1693016276216163e+17, 2.376714761157556e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.2763704285002699e+17, 1.2763704285002699e+17, 1.27637042850027e+17], [1.2763704285002699e+17, 1.2763704285002699e+17, 1.27637042850027e+17], [1.2763704285002699e+17, 1.2763704285002699e+17, 1.27637042850027e+17]]\n",
            "New Weights of hidden layer [[-2.248829004282878e+17, 2.4703271372211738e+17], [-2.248829004282878e+17, 2.4703271372211738e+17], [-2.248829004282878e+17, 2.4703271372211738e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.3134853706066074e+17, 1.3134853706066074e+17, 1.3134853706066075e+17], [1.3134853706066074e+17, 1.3134853706066074e+17, 1.3134853706066075e+17], [1.3134853706066074e+17, 1.3134853706066074e+17, 1.3134853706066075e+17]]\n",
            "New Weights of hidden layer [[-2.1504709427792496e+17, 2.311067917821365e+17], [-2.1504709427792496e+17, 2.311067917821365e+17], [-2.1504709427792496e+17, 2.311067917821365e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.4391666826058784e+17, 1.4391666826058784e+17, 1.4391666826058786e+17], [1.4391666826058784e+17, 1.4391666826058784e+17, 1.4391666826058786e+17], [1.4391666826058784e+17, 1.4391666826058784e+17, 1.4391666826058786e+17]]\n",
            "New Weights of hidden layer [[-2.2401417376286867e+17, 2.4166202008436464e+17], [-2.2401417376286867e+17, 2.4166202008436464e+17], [-2.2401417376286867e+17, 2.4166202008436464e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.4501228272018714e+17, 1.4501228272018714e+17, 1.4501228272018714e+17], [1.4501228272018714e+17, 1.4501228272018714e+17, 1.4501228272018714e+17], [1.4501228272018714e+17, 1.4501228272018714e+17, 1.4501228272018714e+17]]\n",
            "New Weights of hidden layer [[-1.9657656823201507e+17, 2.216606731143724e+17], [-1.9657656823201507e+17, 2.216606731143724e+17], [-1.9657656823201507e+17, 2.216606731143724e+17]]\n",
            "Iteration 13\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.5822082083367248e+17, 1.5822082083367248e+17, 1.5822082083367248e+17], [1.5822082083367248e+17, 1.5822082083367248e+17, 1.5822082083367248e+17], [1.5822082083367248e+17, 1.5822082083367248e+17, 1.5822082083367248e+17]]\n",
            "New Weights of hidden layer [[-2.209058528126107e+17, 2.218292768098503e+17], [-2.209058528126107e+17, 2.218292768098503e+17], [-2.209058528126107e+17, 2.218292768098503e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.7172534486168208e+17, 1.7172534486168208e+17, 1.7172534486168208e+17], [1.7172534486168208e+17, 1.7172534486168208e+17, 1.7172534486168208e+17], [1.7172534486168208e+17, 1.7172534486168208e+17, 1.7172534486168208e+17]]\n",
            "New Weights of hidden layer [[-2.3160561980670096e+17, 2.344240668519034e+17], [-2.3160561980670096e+17, 2.344240668519034e+17], [-2.3160561980670096e+17, 2.344240668519034e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.7718063615352208e+17, 1.7718063615352208e+17, 1.7718063615352208e+17], [1.7718063615352208e+17, 1.7718063615352208e+17, 1.7718063615352208e+17], [1.7718063615352208e+17, 1.7718063615352208e+17, 1.7718063615352208e+17]]\n",
            "New Weights of hidden layer [[-2.1833775683842765e+17, 2.1294103366551955e+17], [-2.1833775683842765e+17, 2.1294103366551955e+17], [-2.1833775683842765e+17, 2.1294103366551955e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.9135295029469088e+17, 1.9135295029469088e+17, 1.9135295029469088e+17], [1.9135295029469088e+17, 1.9135295029469088e+17, 1.9135295029469088e+17], [1.9135295029469088e+17, 1.9135295029469088e+17, 1.9135295029469088e+17]]\n",
            "New Weights of hidden layer [[-2.3026046972297043e+17, 2.269753640949052e+17], [-2.3026046972297043e+17, 2.269753640949052e+17], [-2.3026046972297043e+17, 2.269753640949052e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.9437481984478832e+17, 1.9437481984478832e+17, 1.9437481984478832e+17], [1.9437481984478832e+17, 1.9437481984478832e+17, 1.9437481984478832e+17], [1.9437481984478832e+17, 1.9437481984478832e+17, 1.9437481984478832e+17]]\n",
            "New Weights of hidden layer [[-1.9348303589467302e+17, 2.001655095017803e+17], [-1.9348303589467302e+17, 2.001655095017803e+17], [-1.9348303589467302e+17, 2.001655095017803e+17]]\n",
            "Iteration 14\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.0946769269335242e+17, 2.0946769269335242e+17, 2.0946769269335242e+17], [2.0946769269335242e+17, 2.0946769269335242e+17, 2.0946769269335242e+17], [2.0946769269335242e+17, 2.0946769269335242e+17, 2.0946769269335242e+17]]\n",
            "New Weights of hidden layer [[-2.2569244473938272e+17, 2.0038872302630406e+17], [-2.2569244473938272e+17, 2.0038872302630406e+17], [-2.2569244473938272e+17, 2.0038872302630406e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.2488169961596294e+17, 2.2488169961596294e+17, 2.2488169961596294e+17], [2.2488169961596294e+17, 2.2488169961596294e+17, 2.2488169961596294e+17], [2.2488169961596294e+17, 2.2488169961596294e+17, 2.2488169961596294e+17]]\n",
            "New Weights of hidden layer [[-2.3970424823329264e+17, 2.1688214042630662e+17], [-2.3970424823329264e+17, 2.1688214042630662e+17], [-2.3970424823329264e+17, 2.1688214042630662e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.3267248548637027e+17, 2.3267248548637027e+17, 2.3267248548637027e+17], [2.3267248548637027e+17, 2.3267248548637027e+17, 2.3267248548637027e+17], [2.3267248548637027e+17, 2.3267248548637027e+17, 2.3267248548637027e+17]]\n",
            "New Weights of hidden layer [[-2.2228097489519568e+17, 1.8867075776183174e+17], [-2.2228097489519568e+17, 1.8867075776183174e+17], [-2.2228097489519568e+17, 1.8867075776183174e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.489614229890308e+17, 2.489614229890308e+17, 2.489614229890308e+17], [2.489614229890308e+17, 2.489614229890308e+17, 2.489614229890308e+17], [2.489614229890308e+17, 2.489614229890308e+17, 2.489614229890308e+17]]\n",
            "New Weights of hidden layer [[-2.377931243606423e+17, 2.069302456297596e+17], [-2.377931243606423e+17, 2.069302456297596e+17], [-2.377931243606423e+17, 2.069302456297596e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.545443935939954e+17, 2.545443935939954e+17, 2.545443935939954e+17], [2.545443935939954e+17, 2.545443935939954e+17, 2.545443935939954e+17], [2.545443935939954e+17, 2.545443935939954e+17, 2.545443935939954e+17]]\n",
            "New Weights of hidden layer [[-1.8963107539132326e+17, 1.7182128354712205e+17], [-1.8963107539132326e+17, 1.7182128354712205e+17], [-1.8963107539132326e+17, 1.7182128354712205e+17]]\n",
            "Iteration 15\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.7211107935687104e+17, 2.7211107935687104e+17, 2.7211107935687104e+17], [2.7211107935687104e+17, 2.7211107935687104e+17, 2.7211107935687104e+17], [2.7211107935687104e+17, 2.7211107935687104e+17, 2.7211107935687104e+17]]\n",
            "New Weights of hidden layer [[-2.314730267370682e+17, 1.721112512853648e+17], [-2.314730267370682e+17, 1.721112512853648e+17], [-2.314730267370682e+17, 1.721112512853648e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.900137414631547e+17, 2.900137414631547e+17, 2.900137414631547e+17], [2.900137414631547e+17, 2.900137414631547e+17, 2.900137414631547e+17], [2.900137414631547e+17, 2.900137414631547e+17, 2.900137414631547e+17]]\n",
            "New Weights of hidden layer [[-2.4954304116178515e+17, 1.9338162454320147e+17], [-2.4954304116178515e+17, 1.9338162454320147e+17], [-2.4954304116178515e+17, 1.9338162454320147e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.008598415250712e+17, 3.008598415250712e+17, 3.008598415250712e+17], [3.008598415250712e+17, 3.008598415250712e+17, 3.008598415250712e+17], [3.008598415250712e+17, 3.008598415250712e+17, 3.008598415250712e+17]]\n",
            "New Weights of hidden layer [[-2.2701367657279974e+17, 1.5690257073546512e+17], [-2.2701367657279974e+17, 1.5690257073546512e+17], [-2.2701367657279974e+17, 1.5690257073546512e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.198913706854791e+17, 3.198913706854791e+17, 3.198913706854791e+17], [3.198913706854791e+17, 3.198913706854791e+17, 3.198913706854791e+17], [3.198913706854791e+17, 3.198913706854791e+17, 3.198913706854791e+17]]\n",
            "New Weights of hidden layer [[-2.4694528965246298e+17, 1.803642481791375e+17], [-2.4694528965246298e+17, 1.803642481791375e+17], [-2.4694528965246298e+17, 1.803642481791375e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.28811875668618e+17, 3.28811875668618e+17, 3.28811875668618e+17], [3.28811875668618e+17, 3.28811875668618e+17, 3.28811875668618e+17], [3.28811875668618e+17, 3.28811875668618e+17, 3.28811875668618e+17]]\n",
            "New Weights of hidden layer [[-1.847311766875362e+17, 1.3501167328179446e+17], [-1.847311766875362e+17, 1.3501167328179446e+17], [-1.847311766875362e+17, 1.3501167328179446e+17]]\n",
            "Iteration 16\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.495746409993037e+17, 3.495746409993037e+17, 3.495746409993037e+17], [3.495746409993037e+17, 3.495746409993037e+17, 3.495746409993037e+17], [3.495746409993037e+17, 3.495746409993037e+17, 3.495746409993037e+17]]\n",
            "New Weights of hidden layer [[-2.384845378331737e+17, 1.3538418794836798e+17], [-2.384845378331737e+17, 1.3538418794836798e+17], [-2.384845378331737e+17, 1.3538418794836798e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.706789931005211e+17, 3.706789931005211e+17, 3.706789931005211e+17], [3.706789931005211e+17, 3.706789931005211e+17, 3.706789931005211e+17], [3.706789931005211e+17, 3.706789931005211e+17, 3.706789931005211e+17]]\n",
            "New Weights of hidden layer [[-2.6158059775941328e+17, 1.6257076366822518e+17], [-2.6158059775941328e+17, 1.6257076366822518e+17], [-2.6158059775941328e+17, 1.6257076366822518e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.854677152058926e+17, 3.854677152058926e+17, 3.854677152058926e+17], [3.854677152058926e+17, 3.854677152058926e+17, 3.854677152058926e+17], [3.854677152058926e+17, 3.854677152058926e+17, 3.854677152058926e+17]]\n",
            "New Weights of hidden layer [[-2.3271552009023866e+17, 1.1583306197675774e+17], [-2.3271552009023866e+17, 1.1583306197675774e+17], [-2.3271552009023866e+17, 1.1583306197675774e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.080155372978421e+17, 4.080155372978421e+17, 4.080155372978421e+17], [4.080155372978421e+17, 4.080155372978421e+17, 4.080155372978421e+17], [4.080155372978421e+17, 4.080155372978421e+17, 4.080155372978421e+17]]\n",
            "New Weights of hidden layer [[-2.5813792458487997e+17, 1.457579983936912e+17], [-2.5813792458487997e+17, 1.457579983936912e+17], [-2.5813792458487997e+17, 1.457579983936912e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.212340441708862e+17, 4.212340441708862e+17, 4.212340441708862e+17], [4.212340441708862e+17, 4.212340441708862e+17, 4.212340441708862e+17], [4.212340441708862e+17, 4.212340441708862e+17, 4.212340441708862e+17]]\n",
            "New Weights of hidden layer [[-1.784367204984071e+17, 8.765775946915734e+16], [-1.784367204984071e+17, 8.765775946915734e+16], [-1.784367204984071e+17, 8.765775946915734e+16]]\n",
            "Iteration 17\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.460873999385958e+17, 4.460873999385958e+17, 4.460873999385958e+17], [4.460873999385958e+17, 4.460873999385958e+17, 4.460873999385958e+17], [4.460873999385958e+17, 4.460873999385958e+17, 4.460873999385958e+17]]\n",
            "New Weights of hidden layer [[-2.4703064665641334e+17, 8.813312032077902e+16], [-2.4703064665641334e+17, 8.813312032077902e+16], [-2.4703064665641334e+17, 8.813312032077902e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.712792744447594e+17, 4.712792744447594e+17, 4.712792744447594e+17], [4.712792744447594e+17, 4.712792744447594e+17, 4.712792744447594e+17], [4.712792744447594e+17, 4.712792744447594e+17, 4.712792744447594e+17]]\n",
            "New Weights of hidden layer [[-2.7639485279479344e+17, 1.2269798619764656e+17], [-2.7639485279479344e+17, 1.2269798619764656e+17], [-2.7639485279479344e+17, 1.2269798619764656e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.911138782927706e+17, 4.911138782927706e+17, 4.911138782927706e+17], [4.911138782927706e+17, 4.911138782927706e+17, 4.911138782927706e+17], [4.911138782927706e+17, 4.911138782927706e+17, 4.911138782927706e+17]]\n",
            "New Weights of hidden layer [[-2.396186464301218e+17, 6.31507581556643e+16], [-2.396186464301218e+17, 6.31507581556643e+16], [-2.396186464301218e+17, 6.31507581556643e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.1814166028535e+17, 5.1814166028535e+17, 5.1814166028535e+17], [5.1814166028535e+17, 5.1814166028535e+17, 5.1814166028535e+17], [5.1814166028535e+17, 5.1814166028535e+17, 5.1814166028535e+17]]\n",
            "New Weights of hidden layer [[-2.719027279642121e+17, 1.0115263509812218e+17], [-2.719027279642121e+17, 1.0115263509812218e+17], [-2.719027279642121e+17, 1.0115263509812218e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.368551189250321e+17, 5.368551189250321e+17, 5.368551189250321e+17], [5.368551189250321e+17, 5.368551189250321e+17, 5.368551189250321e+17], [5.368551189250321e+17, 5.368551189250321e+17, 5.368551189250321e+17]]\n",
            "New Weights of hidden layer [[-1.703249946579425e+17, 2.710493855261296e+16], [-1.703249946579425e+17, 2.710493855261296e+16], [-1.703249946579425e+17, 2.710493855261296e+16]]\n",
            "Iteration 18\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.6691463815966835e+17, 5.6691463815966835e+17, 5.6691463815966835e+17], [5.6691463815966835e+17, 5.6691463815966835e+17, 5.6691463815966835e+17], [5.6691463815966835e+17, 5.6691463815966835e+17, 5.6691463815966835e+17]]\n",
            "New Weights of hidden layer [[-2.5749827243527923e+17, 2.770905564991155e+16], [-2.5749827243527923e+17, 2.770905564991155e+16], [-2.5749827243527923e+17, 2.770905564991155e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.973009965314351e+17, 5.973009965314351e+17, 5.973009965314351e+17], [5.973009965314351e+17, 5.973009965314351e+17, 5.973009965314351e+17], [5.973009965314351e+17, 5.973009965314351e+17, 5.973009965314351e+17]]\n",
            "New Weights of hidden layer [[-2.94714569734737e+17, 7.151668724489766e+16], [-2.94714569734737e+17, 7.151668724489766e+16], [-2.94714569734737e+17, 7.151668724489766e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.235609016251182e+17, 6.235609016251182e+17, 6.235609016251182e+17], [6.235609016251182e+17, 6.235609016251182e+17, 6.235609016251182e+17], [6.235609016251182e+17, 6.235609016251182e+17, 6.235609016251182e+17]]\n",
            "New Weights of hidden layer [[-2.4802029899080304e+17, -4089653460057248.0], [-2.4802029899080304e+17, -4089653460057248.0], [-2.4802029899080304e+17, -4089653460057248.0]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.562748424469644e+17, 6.562748424469644e+17, 6.562748424469644e+17], [6.562748424469644e+17, 6.562748424469644e+17, 6.562748424469644e+17], [6.562748424469644e+17, 6.562748424469644e+17, 6.562748424469644e+17]]\n",
            "New Weights of hidden layer [[-2.889111057841843e+17, 4.404327564926343e+16], [-2.889111057841843e+17, 4.404327564926343e+16], [-2.889111057841843e+17, 4.404327564926343e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.8198199811784e+17, 6.8198199811784e+17, 6.8198199811784e+17], [6.8198199811784e+17, 6.8198199811784e+17, 6.8198199811784e+17], [6.8198199811784e+17, 6.8198199811784e+17, 6.8198199811784e+17]]\n",
            "New Weights of hidden layer [[-1.5987408428162058e+17, -5.0021574001879944e+16], [-1.5987408428162058e+17, -5.0021574001879944e+16], [-1.5987408428162058e+17, -5.0021574001879944e+16]]\n",
            "Iteration 19\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.186451611229741e+17, 7.186451611229741e+17, 7.186451611229741e+17], [7.186451611229741e+17, 7.186451611229741e+17, 7.186451611229741e+17], [7.186451611229741e+17, 7.186451611229741e+17, 7.186451611229741e+17]]\n",
            "New Weights of hidden layer [[-2.703786471154133e+17, -4.92557694177284e+16], [-2.703786471154133e+17, -4.92557694177284e+16], [-2.703786471154133e+17, -4.92557694177284e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.55614459301387e+17, 7.55614459301387e+17, 7.55614459301387e+17], [7.55614459301387e+17, 7.55614459301387e+17, 7.55614459301387e+17], [7.55614459301387e+17, 7.55614459301387e+17, 7.55614459301387e+17]]\n",
            "New Weights of hidden layer [[-3.1745905134114016e+17, 6162989387536184.0], [-3.1745905134114016e+17, 6162989387536184.0], [-3.1745905134114016e+17, 6162989387536184.0]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.90030482748607e+17, 7.90030482748607e+17, 7.90030482748607e+17], [7.90030482748607e+17, 7.90030482748607e+17, 7.90030482748607e+17], [7.90030482748607e+17, 7.90030482748607e+17, 7.90030482748607e+17]]\n",
            "New Weights of hidden layer [[-2.5829899630676864e+17, -8.962767627209709e+16], [-2.5829899630676864e+17, -8.962767627209709e+16], [-2.5829899630676864e+17, -8.962767627209709e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[8.299450810899932e+17, 8.299450810899932e+17, 8.299450810899932e+17], [8.299450810899932e+17, 8.299450810899932e+17, 8.299450810899932e+17], [8.299450810899932e+17, 8.299450810899932e+17, 8.299450810899932e+17]]\n",
            "New Weights of hidden layer [[-3.1001075145104826e+17, -2.875731347746909e+16], [-3.1001075145104826e+17, -2.875731347746909e+16], [-3.1001075145104826e+17, -2.875731347746909e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[8.645282156018828e+17, 8.645282156018828e+17, 8.645282156018828e+17], [8.645282156018828e+17, 8.645282156018828e+17, 8.645282156018828e+17], [8.645282156018828e+17, 8.645282156018828e+17, 8.645282156018828e+17]]\n",
            "New Weights of hidden layer [[-1.4643437222979293e+17, -1.4800051468248208e+17], [-1.4643437222979293e+17, -1.4800051468248208e+17], [-1.4643437222979293e+17, -1.4800051468248208e+17]]\n",
            "Iteration 20\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.095506014997965e+17, 9.095506014997965e+17, 9.095506014997965e+17], [9.095506014997965e+17, 9.095506014997965e+17, 9.095506014997965e+17], [9.095506014997965e+17, 9.095506014997965e+17, 9.095506014997965e+17]]\n",
            "New Weights of hidden layer [[-2.8629406520662925e+17, -1.4703127693090813e+17], [-2.8629406520662925e+17, -1.4703127693090813e+17], [-2.8629406520662925e+17, -1.4703127693090813e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.548484817686305e+17, 9.548484817686305e+17, 9.548484817686305e+17], [9.548484817686305e+17, 9.548484817686305e+17, 9.548484817686305e+17], [9.548484817686305e+17, 9.548484817686305e+17, 9.548484817686305e+17]]\n",
            "New Weights of hidden layer [[-3.457882317655277e+17, -7.700016906191174e+16], [-3.457882317655277e+17, -7.700016906191174e+16], [-3.457882317655277e+17, -7.700016906191174e+16]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.99597209356724e+17, 9.99597209356724e+17, 9.99597209356724e+17], [9.99597209356724e+17, 9.99597209356724e+17, 9.99597209356724e+17], [9.99597209356724e+17, 9.99597209356724e+17, 9.99597209356724e+17]]\n",
            "New Weights of hidden layer [[-2.7093513785451014e+17, -1.982006596336931e+17], [-2.7093513785451014e+17, -1.982006596336931e+17], [-2.7093513785451014e+17, -1.982006596336931e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.0486178195491116e+18, 1.0486178195491116e+18, 1.0486178195491116e+18], [1.0486178195491116e+18, 1.0486178195491116e+18, 1.0486178195491116e+18], [1.0486178195491116e+18, 1.0486178195491116e+18, 1.0486178195491116e+18]]\n",
            "New Weights of hidden layer [[-3.362718320044839e+17, -1.212922610381661e+17], [-3.362718320044839e+17, -1.212922610381661e+17], [-3.362718320044839e+17, -1.212922610381661e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.0944453780425066e+18, 1.0944453780425066e+18, 1.0944453780425066e+18], [1.0944453780425066e+18, 1.0944453780425066e+18, 1.0944453780425066e+18], [1.0944453780425066e+18, 1.0944453780425066e+18, 1.0944453780425066e+18]]\n",
            "New Weights of hidden layer [[-1.2919309360727142e+17, -2.7224762382058458e+17], [-1.2919309360727142e+17, -2.7224762382058458e+17], [-1.2919309360727142e+17, -2.7224762382058458e+17]]\n",
            "Iteration 21\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.1500363574011466e+18, 1.1500363574011466e+18, 1.1500363574011466e+18], [1.1500363574011466e+18, 1.1500363574011466e+18, 1.1500363574011466e+18], [1.1500363574011466e+18, 1.1500363574011466e+18, 1.1500363574011466e+18]]\n",
            "New Weights of hidden layer [[-3.060317781104772e+17, -2.7102211899277424e+17], [-3.060317781104772e+17, -2.7102211899277424e+17], [-3.060317781104772e+17, -2.7102211899277424e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.2058607935756183e+18, 1.2058607935756183e+18, 1.2058607935756183e+18], [1.2058607935756183e+18, 1.2058607935756183e+18, 1.2058607935756183e+18], [1.2058607935756183e+18, 1.2058607935756183e+18, 1.2058607935756183e+18]]\n",
            "New Weights of hidden layer [[-3.8116587977124416e+17, -1.825811056568487e+17], [-3.8116587977124416e+17, -1.825811056568487e+17], [-3.8116587977124416e+17, -1.825811056568487e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.263683229292321e+18, 1.263683229292321e+18, 1.263683229292321e+18], [1.263683229292321e+18, 1.263683229292321e+18, 1.263683229292321e+18], [1.263683229292321e+18, 1.263683229292321e+18, 1.263683229292321e+18]]\n",
            "New Weights of hidden layer [[-2.8653716477426214e+17, -3.3580184885612736e+17], [-2.8653716477426214e+17, -3.3580184885612736e+17], [-2.8653716477426214e+17, -3.3580184885612736e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.3242099059480812e+18, 1.3242099059480812e+18, 1.3242099059480812e+18], [1.3242099059480812e+18, 1.3242099059480812e+18, 1.3242099059480812e+18], [1.3242099059480812e+18, 1.3242099059480812e+18, 1.3242099059480812e+18]]\n",
            "New Weights of hidden layer [[-3.6904529691004563e+17, -2.386807992495213e+17], [-3.6904529691004563e+17, -2.386807992495213e+17], [-3.6904529691004563e+17, -2.386807992495213e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.3842656040913974e+18, 1.3842656040913974e+18, 1.3842656040913974e+18], [1.3842656040913974e+18, 1.3842656040913974e+18, 1.3842656040913974e+18], [1.3842656040913974e+18, 1.3842656040913974e+18, 1.3842656040913974e+18]]\n",
            "New Weights of hidden layer [[-1.0713001026997664e+17, -4.296106717175146e+17], [-1.0713001026997664e+17, -4.296106717175146e+17], [-1.0713001026997664e+17, -4.296106717175146e+17]]\n",
            "Iteration 22\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.4532087492269532e+18, 1.4532087492269532e+18, 1.4532087492269532e+18], [1.4532087492269532e+18, 1.4532087492269532e+18, 1.4532087492269532e+18], [1.4532087492269532e+18, 1.4532087492269532e+18, 1.4532087492269532e+18]]\n",
            "New Weights of hidden layer [[-3.305868791489528e+17, -4.280620995123555e+17], [-3.305868791489528e+17, -4.280620995123555e+17], [-3.305868791489528e+17, -4.280620995123555e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.522329831516808e+18, 1.522329831516808e+18, 1.522329831516808e+18], [1.522329831516808e+18, 1.522329831516808e+18, 1.522329831516808e+18], [1.522329831516808e+18, 1.522329831516808e+18, 1.522329831516808e+18]]\n",
            "New Weights of hidden layer [[-4.254393570898318e+17, -3.164104116490894e+17], [-4.254393570898318e+17, -3.164104116490894e+17], [-4.254393570898318e+17, -3.164104116490894e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.5966807929605563e+18, 1.5966807929605563e+18, 1.5966807929605563e+18], [1.5966807929605563e+18, 1.5966807929605563e+18, 1.5966807929605563e+18], [1.5966807929605563e+18, 1.5966807929605563e+18, 1.5966807929605563e+18]]\n",
            "New Weights of hidden layer [[-3.058747002233851e+17, -5.100068858908455e+17], [-3.058747002233851e+17, -5.100068858908455e+17], [-3.058747002233851e+17, -5.100068858908455e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.6717390845683658e+18, 1.6717390845683658e+18, 1.6717390845683658e+18], [1.6717390845683658e+18, 1.6717390845683658e+18, 1.6717390845683658e+18], [1.6717390845683658e+18, 1.6717390845683658e+18, 1.6717390845683658e+18]]\n",
            "New Weights of hidden layer [[-4.100364865584349e+17, -3.873971290597165e+17], [-4.100364865584349e+17, -3.873971290597165e+17], [-4.100364865584349e+17, -3.873971290597165e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.7497845332539395e+18, 1.7497845332539395e+18, 1.7497845332539395e+18], [1.7497845332539395e+18, 1.7497845332539395e+18, 1.7497845332539395e+18], [1.7497845332539395e+18, 1.7497845332539395e+18, 1.7497845332539395e+18]]\n",
            "New Weights of hidden layer [[-7.896178800997222e+16, -6.287425303997498e+17], [-7.896178800997222e+16, -6.287425303997498e+17], [-7.896178800997222e+16, -6.287425303997498e+17]]\n",
            "Iteration 23\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.8355893091315267e+18, 1.8355893091315267e+18, 1.8355893091315267e+18], [1.8355893091315267e+18, 1.8355893091315267e+18, 1.8355893091315267e+18], [1.8355893091315267e+18, 1.8355893091315267e+18, 1.8355893091315267e+18]]\n",
            "New Weights of hidden layer [[-3.612165155461573e+17, -6.26786484796721e+17], [-3.612165155461573e+17, -6.26786484796721e+17], [-3.612165155461573e+17, -6.26786484796721e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.9215001971936822e+18, 1.9215001971936822e+18, 1.9215001971936822e+18], [1.9215001971936822e+18, 1.9215001971936822e+18, 1.9215001971936822e+18], [1.9215001971936822e+18, 1.9215001971936822e+18, 1.9215001971936822e+18]]\n",
            "New Weights of hidden layer [[-4.8094027796242054e+17, -4.8585858874904736e+17], [-4.8094027796242054e+17, -4.8585858874904736e+17], [-4.8094027796242054e+17, -4.8585858874904736e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.0167365991264317e+18, 2.0167365991264317e+18, 2.0167365991264317e+18], [2.0167365991264317e+18, 2.0167365991264317e+18, 2.0167365991264317e+18], [2.0167365991264317e+18, 2.0167365991264317e+18, 2.0167365991264317e+18]]\n",
            "New Weights of hidden layer [[-3.299204745504599e+17, -7.303865474910374e+17], [-3.299204745504599e+17, -7.303865474910374e+17], [-3.299204745504599e+17, -7.303865474910374e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.1101424188328637e+18, 2.1101424188328637e+18, 2.1101424188328637e+18], [2.1101424188328637e+18, 2.1101424188328637e+18, 2.1101424188328637e+18], [2.1101424188328637e+18, 2.1101424188328637e+18, 2.1101424188328637e+18]]\n",
            "New Weights of hidden layer [[-4.613980512823242e+17, -5.7562313300823917e+17], [-4.613980512823242e+17, -5.7562313300823917e+17], [-4.613980512823242e+17, -5.7562313300823917e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.2109221293299187e+18, 2.2109221293299187e+18, 2.2109221293299187e+18], [2.2109221293299187e+18, 2.2109221293299187e+18, 2.2109221293299187e+18], [2.2109221293299187e+18, 2.2109221293299187e+18, 2.2109221293299187e+18]]\n",
            "New Weights of hidden layer [[-4.307204395339878e+16, -8.805726159268035e+17], [-4.307204395339878e+16, -8.805726159268035e+17], [-4.307204395339878e+16, -8.805726159268035e+17]]\n",
            "Iteration 24\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.3180151320291727e+18, 2.3180151320291727e+18, 2.3180151320291727e+18], [2.3180151320291727e+18, 2.3180151320291727e+18, 2.3180151320291727e+18], [2.3180151320291727e+18, 2.3180151320291727e+18, 2.3180151320291727e+18]]\n",
            "New Weights of hidden layer [[-3.995083809165966e+17, -8.781024864244122e+17], [-3.995083809165966e+17, -8.781024864244122e+17], [-3.995083809165966e+17, -8.781024864244122e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.4251224027141407e+18, 2.4251224027141407e+18, 2.4251224027141407e+18], [2.4251224027141407e+18, 2.4251224027141407e+18, 2.4251224027141407e+18], [2.4251224027141407e+18, 2.4251224027141407e+18, 2.4251224027141407e+18]]\n",
            "New Weights of hidden layer [[-5.50611554778847e+17, -7.002376085692193e+17], [-5.50611554778847e+17, -7.002376085692193e+17], [-5.50611554778847e+17, -7.002376085692193e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.546740689589329e+18, 2.546740689589329e+18, 2.546740689589329e+18], [2.546740689589329e+18, 2.546740689589329e+18, 2.546740689589329e+18], [2.546740689589329e+18, 2.546740689589329e+18, 2.546740689589329e+18]]\n",
            "New Weights of hidden layer [[-3.599033192811533e+17, -1.0090282074705318e+18], [-3.599033192811533e+17, -1.0090282074705318e+18], [-3.599033192811533e+17, -1.0090282074705318e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.663308247923918e+18, 2.663308247923918e+18, 2.663308247923918e+18], [2.663308247923918e+18, 2.663308247923918e+18, 2.663308247923918e+18], [2.663308247923918e+18, 2.663308247923918e+18, 2.663308247923918e+18]]\n",
            "New Weights of hidden layer [[-5.2584724391952115e+17, -8.136941510626776e+17], [-5.2584724391952115e+17, -8.136941510626776e+17], [-5.2584724391952115e+17, -8.136941510626776e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.7928081893496064e+18, 2.7928081893496064e+18, 2.7928081893496064e+18], [2.7928081893496064e+18, 2.7928081893496064e+18, 2.7928081893496064e+18], [2.7928081893496064e+18, 2.7928081893496064e+18, 2.7928081893496064e+18]]\n",
            "New Weights of hidden layer [[2576748760959936.0, -1.1989023869995151e+18], [2576748760959936.0, -1.1989023869995151e+18], [2576748760959936.0, -1.1989023869995151e+18]]\n",
            "Iteration 25\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[2.926774353650282e+18, 2.926774353650282e+18, 2.926774353650282e+18], [2.926774353650282e+18, 2.926774353650282e+18, 2.926774353650282e+18], [2.926774353650282e+18, 2.926774353650282e+18, 2.926774353650282e+18]]\n",
            "New Weights of hidden layer [[-4.474672200287177e+17, -1.1957835498625613e+18], [-4.474672200287177e+17, -1.1957835498625613e+18], [-4.474672200287177e+17, -1.1957835498625613e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.0606381162600033e+18, 3.0606381162600033e+18, 3.0606381162600033e+18], [3.0606381162600033e+18, 3.0606381162600033e+18, 3.0606381162600033e+18], [3.0606381162600033e+18, 3.0606381162600033e+18, 3.0606381162600033e+18]]\n",
            "New Weights of hidden layer [[-6.381677524608447e+17, -9.713082722030604e+17], [-6.381677524608447e+17, -9.713082722030604e+17], [-6.381677524608447e+17, -9.713082722030604e+17]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.2155737823236884e+18, 3.2155737823236884e+18, 3.2155737823236884e+18], [3.2155737823236884e+18, 3.2155737823236884e+18, 3.2155737823236884e+18], [3.2155737823236884e+18, 3.2155737823236884e+18, 3.2155737823236884e+18]]\n",
            "New Weights of hidden layer [[-3.9737511713428454e+17, -1.3611944345886016e+18], [-3.9737511713428454e+17, -1.3611944345886016e+18], [-3.9737511713428454e+17, -1.3611944345886016e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.3613779127860173e+18, 3.3613779127860173e+18, 3.3613779127860173e+18], [3.3613779127860173e+18, 3.3613779127860173e+18, 3.3613779127860173e+18], [3.3613779127860173e+18, 3.3613779127860173e+18, 3.3613779127860173e+18]]\n",
            "New Weights of hidden layer [[-6.068139770466696e+17, -1.1146621064827277e+18], [-6.068139770466696e+17, -1.1146621064827277e+18], [-6.068139770466696e+17, -1.1146621064827277e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.527151711478854e+18, 3.527151711478854e+18, 3.527151711478854e+18], [3.527151711478854e+18, 3.527151711478854e+18, 3.527151711478854e+18], [3.527151711478854e+18, 3.527151711478854e+18, 3.527151711478854e+18]]\n",
            "New Weights of hidden layer [[6.055430025829658e+16, -1.6011573458771594e+18], [6.055430025829658e+16, -1.6011573458771594e+18], [6.055430025829658e+16, -1.6011573458771594e+18]]\n",
            "Iteration 26\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.6950386316368364e+18, 3.6950386316368364e+18, 3.6950386316368364e+18], [3.6950386316368364e+18, 3.6950386316368364e+18, 3.6950386316368364e+18], [3.6950386316368364e+18, 3.6950386316368364e+18, 3.6950386316368364e+18]]\n",
            "New Weights of hidden layer [[-5.076240591492233e+17, -1.597219828899653e+18], [-5.076240591492233e+17, -1.597219828899653e+18], [-5.076240591492233e+17, -1.597219828899653e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[3.8626754950846587e+18, 3.8626754950846587e+18, 3.8626754950846587e+18], [3.8626754950846587e+18, 3.8626754950846587e+18, 3.8626754950846587e+18], [3.8626754950846587e+18, 3.8626754950846587e+18, 3.8626754950846587e+18]]\n",
            "New Weights of hidden layer [[-7.482974891806351e+17, -1.313921012988932e+18], [-7.482974891806351e+17, -1.313921012988932e+18], [-7.482974891806351e+17, -1.313921012988932e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.0596810134899374e+18, 4.0596810134899374e+18, 4.0596810134899374e+18], [4.0596810134899374e+18, 4.0596810134899374e+18, 4.0596810134899374e+18], [4.0596810134899374e+18, 4.0596810134899374e+18, 4.0596810134899374e+18]]\n",
            "New Weights of hidden layer [[-4.442953558142422e+17, -1.806154610476233e+18], [-4.442953558142422e+17, -1.806154610476233e+18], [-4.442953558142422e+17, -1.806154610476233e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.242388185539181e+18, 4.242388185539181e+18, 4.242388185539181e+18], [4.242388185539181e+18, 4.242388185539181e+18, 4.242388185539181e+18], [4.242388185539181e+18, 4.242388185539181e+18, 4.242388185539181e+18]]\n",
            "New Weights of hidden layer [[-7.086277123473592e+17, -1.4950066636382756e+18], [-7.086277123473592e+17, -1.4950066636382756e+18], [-7.086277123473592e+17, -1.4950066636382756e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.453968741429937e+18, 4.453968741429937e+18, 4.453968741429937e+18], [4.453968741429937e+18, 4.453968741429937e+18, 4.453968741429937e+18], [4.453968741429937e+18, 4.453968741429937e+18, 4.453968741429937e+18]]\n",
            "New Weights of hidden layer [[1.3410253837156723e+17, -2.1093365157014774e+18], [1.3410253837156723e+17, -2.1093365157014774e+18], [1.3410253837156723e+17, -2.1093365157014774e+18]]\n",
            "Iteration 27\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.664670687989016e+18, 4.664670687989016e+18, 4.664670687989016e+18], [4.664670687989016e+18, 4.664670687989016e+18, 4.664670687989016e+18], [4.664670687989016e+18, 4.664670687989016e+18, 4.664670687989016e+18]]\n",
            "New Weights of hidden layer [[-5.831741136194515e+17, -2.1043657368113262e+18], [-5.831741136194515e+17, -2.1043657368113262e+18], [-5.831741136194515e+17, -2.1043657368113262e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[4.874936088824193e+18, 4.874936088824193e+18, 4.874936088824193e+18], [4.874936088824193e+18, 4.874936088824193e+18, 4.874936088824193e+18], [4.874936088824193e+18, 4.874936088824193e+18, 4.874936088824193e+18]]\n",
            "New Weights of hidden layer [[-8.869189120562458e+17, -1.7468250572067955e+18], [-8.869189120562458e+17, -1.7468250572067955e+18], [-8.869189120562458e+17, -1.7468250572067955e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.125057843431194e+18, 5.125057843431194e+18, 5.125057843431194e+18], [5.125057843431194e+18, 5.125057843431194e+18, 5.125057843431194e+18], [5.125057843431194e+18, 5.125057843431194e+18, 5.125057843431194e+18]]\n",
            "New Weights of hidden layer [[-5.031378925987893e+17, -2.368234880101714e+18], [-5.031378925987893e+17, -2.368234880101714e+18], [-5.031378925987893e+17, -2.368234880101714e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.354343899974902e+18, 5.354343899974902e+18, 5.354343899974902e+18], [5.354343899974902e+18, 5.354343899974902e+18, 5.354343899974902e+18], [5.354343899974902e+18, 5.354343899974902e+18, 5.354343899974902e+18]]\n",
            "New Weights of hidden layer [[-8.36753365504696e+17, -1.9755331662839352e+18], [-8.36753365504696e+17, -1.9755331662839352e+18], [-8.36753365504696e+17, -1.9755331662839352e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.623762849154959e+18, 5.623762849154959e+18, 5.623762849154959e+18], [5.623762849154959e+18, 5.623762849154959e+18, 5.623762849154959e+18], [5.623762849154959e+18, 5.623762849154959e+18, 5.623762849154959e+18]]\n",
            "New Weights of hidden layer [[2.2731226921069184e+17, -2.751211128956553e+18], [2.2731226921069184e+17, -2.751211128956553e+18], [2.2731226921069184e+17, -2.751211128956553e+18]]\n",
            "Iteration 28\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[5.888505407038265e+18, 5.888505407038265e+18, 5.888505407038265e+18], [5.888505407038265e+18, 5.888505407038265e+18, 5.888505407038265e+18], [5.888505407038265e+18, 5.888505407038265e+18, 5.888505407038265e+18]]\n",
            "New Weights of hidden layer [[-6.781508869488465e+17, -2.7449362040305096e+18], [-6.781508869488465e+17, -2.7449362040305096e+18], [-6.781508869488465e+17, -2.7449362040305096e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.152576131459562e+18, 6.152576131459562e+18, 6.152576131459562e+18], [6.152576131459562e+18, 6.152576131459562e+18, 6.152576131459562e+18], [6.152576131459562e+18, 6.152576131459562e+18, 6.152576131459562e+18]]\n",
            "New Weights of hidden layer [[-1.0615021684562031e+18, -2.293690031510688e+18], [-1.0615021684562031e+18, -2.293690031510688e+18], [-1.0615021684562031e+18, -2.293690031510688e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.469756339393997e+18, 6.469756339393997e+18, 6.469756339393997e+18], [6.469756339393997e+18, 6.469756339393997e+18, 6.469756339393997e+18], [6.469756339393997e+18, 6.469756339393997e+18, 6.469756339393997e+18]]\n",
            "New Weights of hidden layer [[-5.77025747032706e+17, -3.078143644300449e+18], [-5.77025747032706e+17, -3.078143644300449e+18], [-5.77025747032706e+17, -3.078143644300449e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[6.757833721283167e+18, 6.757833721283167e+18, 6.757833721283167e+18], [6.757833721283167e+18, 6.757833721283167e+18, 6.757833721283167e+18], [6.757833721283167e+18, 6.757833721283167e+18, 6.757833721283167e+18]]\n",
            "New Weights of hidden layer [[-9.980890808159424e+17, -2.5825062826330527e+18], [-9.980890808159424e+17, -2.5825062826330527e+18], [-9.980890808159424e+17, -2.5825062826330527e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.100277050256531e+18, 7.100277050256531e+18, 7.100277050256531e+18], [7.100277050256531e+18, 7.100277050256531e+18, 7.100277050256531e+18], [7.100277050256531e+18, 7.100277050256531e+18, 7.100277050256531e+18]]\n",
            "New Weights of hidden layer [[3.4534609040070554e+17, -3.56183784132097e+18], [3.4534609040070554e+17, -3.56183784132097e+18], [3.4534609040070554e+17, -3.56183784132097e+18]]\n",
            "Iteration 29\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.433228786007496e+18, 7.433228786007496e+18, 7.433228786007496e+18], [7.433228786007496e+18, 7.433228786007496e+18, 7.433228786007496e+18], [7.433228786007496e+18, 7.433228786007496e+18, 7.433228786007496e+18]]\n",
            "New Weights of hidden layer [[-7.976459477809354e+17, -3.5539168241245604e+18], [-7.976459477809354e+17, -3.5539168241245604e+18], [-7.976459477809354e+17, -3.5539168241245604e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[7.765211978354932e+18, 7.765211978354932e+18, 7.765211978354932e+18], [7.765211978354932e+18, 7.765211978354932e+18, 7.765211978354932e+18], [7.765211978354932e+18, 7.765211978354932e+18, 7.765211978354932e+18]]\n",
            "New Weights of hidden layer [[-1.2814764440599726e+18, -2.984395682220952e+18], [-1.2814764440599726e+18, -2.984395682220952e+18], [-1.2814764440599726e+18, -2.984395682220952e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[8.167048401893872e+18, 8.167048401893872e+18, 8.167048401893872e+18], [8.167048401893872e+18, 8.167048401893872e+18, 8.167048401893872e+18], [8.167048401893872e+18, 8.167048401893872e+18, 8.167048401893872e+18]]\n",
            "New Weights of hidden layer [[-6.699012662979227e+17, -3.9746448181404324e+18], [-6.699012662979227e+17, -3.9746448181404324e+18], [-6.699012662979227e+17, -3.9746448181404324e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[8.529331587671472e+18, 8.529331587671472e+18, 8.529331587671472e+18], [8.529331587671472e+18, 8.529331587671472e+18, 8.529331587671472e+18], [8.529331587671472e+18, 8.529331587671472e+18, 8.529331587671472e+18]]\n",
            "New Weights of hidden layer [[-1.2013421009454031e+18, -3.349081127281053e+18], [-1.2013421009454031e+18, -3.349081127281053e+18], [-1.2013421009454031e+18, -3.349081127281053e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[8.963967123428718e+18, 8.963967123428718e+18, 8.963967123428718e+18], [8.963967123428718e+18, 8.963967123428718e+18, 8.963967123428718e+18], [8.963967123428718e+18, 8.963967123428718e+18, 8.963967123428718e+18]]\n",
            "New Weights of hidden layer [[4.947197036863995e+17, -4.585468923542823e+18], [4.947197036863995e+17, -4.585468923542823e+18], [4.947197036863995e+17, -4.585468923542823e+18]]\n",
            "Iteration 30\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.383011611060337e+18, 9.383011611060337e+18, 9.383011611060337e+18], [9.383011611060337e+18, 9.383011611060337e+18, 9.383011611060337e+18], [9.383011611060337e+18, 9.383011611060337e+18, 9.383011611060337e+18]]\n",
            "New Weights of hidden layer [[-9.48086360052191e+17, -4.5754701735426575e+18], [-9.48086360052191e+17, -4.5754701735426575e+18], [-9.48086360052191e+17, -4.5754701735426575e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[9.800713453310005e+18, 9.800713453310005e+18, 9.800713453310005e+18], [9.800713453310005e+18, 9.800713453310005e+18, 9.800713453310005e+18], [9.800713453310005e+18, 9.800713453310005e+18, 9.800713453310005e+18]]\n",
            "New Weights of hidden layer [[-1.558743746768914e+18, -3.8566599809866957e+18], [-1.558743746768914e+18, -3.8566599809866957e+18], [-1.558743746768914e+18, -3.8566599809866957e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.030941829734411e+19, 1.030941829734411e+19, 1.030941829734411e+19], [1.030941829734411e+19, 1.030941829734411e+19, 1.030941829734411e+19], [1.030941829734411e+19, 1.030941829734411e+19, 1.030941829734411e+19]]\n",
            "New Weights of hidden layer [[-7.867409352808027e+17, -5.106670028485634e+18], [-7.867409352808027e+17, -5.106670028485634e+18], [-7.867409352808027e+17, -5.106670028485634e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.0765363717625793e+19, 1.0765363717625793e+19, 1.0765363717625793e+19], [1.0765363717625793e+19, 1.0765363717625793e+19, 1.0765363717625793e+19], [1.0765363717625793e+19, 1.0765363717625793e+19, 1.0765363717625793e+19]]\n",
            "New Weights of hidden layer [[-1.457503212555644e+18, -4.3171098394579553e+18], [-1.457503212555644e+18, -4.3171098394579553e+18], [-1.457503212555644e+18, -4.3171098394579553e+18]]\n",
            "Entropy based loss: 1.098612\n",
            "New Weights of output layer [[1.1316385582924413e+19, 1.1316385582924413e+19, 1.1316385582924413e+19], [1.1316385582924413e+19, 1.1316385582924413e+19, 1.1316385582924413e+19], [1.1316385582924413e+19, 1.1316385582924413e+19, 1.1316385582924413e+19]]\n",
            "New Weights of hidden layer [[6.836569556381299e+17, -5.877963515053394e+18], [6.836569556381299e+17, -5.877963515053394e+18], [6.836569556381299e+17, -5.877963515053394e+18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "sS3EIJKe6PyB",
        "outputId": "396d3bb8-d136-43bf-f920-bd2786e18d41"
      },
      "source": [
        "for rowIndex, row in X_test.iterrows():\n",
        "  print(rowIndex)\n",
        "  for layer_idx, layer in enumerate(layers):\n",
        "      output = row\n",
        "      \n",
        "      if layer_idx == len(layers) - 1:\n",
        "        output = layer.calculate_output(output, softmax)\n",
        "      else:\n",
        "        output = layer.calculate_output(output, relu)\n",
        "  print(output)\n",
        "  print((lb.transform([y_test.loc[rowIndex, 'target']])[0]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-d592d505df3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-5395fbc88a3d>\u001b[0m in \u001b[0;36mcalculate_output\u001b[0;34m(self, inputs, activation)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcol_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
          ]
        }
      ]
    }
  ]
}